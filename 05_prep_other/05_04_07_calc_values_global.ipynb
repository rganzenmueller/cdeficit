{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6dd787c-0f84-4fab-900e-70cd25cfef95",
   "metadata": {},
   "source": [
    "# Calculate global carbon stocks for 1700 primary land area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee45e0e-fe4f-4bf0-82ab-245f53bcde98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5368afda-55c3-4659-a182-4f26822bcbc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir05x = '../paper_deficit/output/05_prep_other/fig_dgvm/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251b30c1-6bd7-41fb-a3bd-033ccd30ad58",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87766bfa-ed34-4fcc-8636-01435ef3d0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "ds = xr.open_dataset(os.path.join(dir05x, 'dgvms_and_other_luh2res.nc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6388fe4-5b4c-4790-9657-476271005323",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_ds_carbon_sum_luh2res(m):\n",
    "    \"\"\"Calculate carbon stocks on primary land of dgvm\"\"\"\n",
    "\n",
    "    # Get data\n",
    "    dsm = ds[[i for i in ds.data_vars \n",
    "              if i.startswith(m) and i.endswith(('cveg', 'csoil'))]]\n",
    "    da_land = ds[f'{m}_land']\n",
    "    da_prim = ds.luh2_primary_1700\n",
    "    da_area = ds.grid_cell_area_ha\n",
    "\n",
    "    # Create primary land mask\n",
    "    da_prim_land = xr.where(da_prim == da_prim, 1, 0)\n",
    "    # Calculate carbon stocks\n",
    "    ds_sum = (dsm * da_land * da_prim * da_prim_land * da_area) \\\n",
    "        .sum(['lat', 'lon']) * 0.000000001\n",
    "    # Create dataframe with carbon stocks of vegetation, soil and litter of\n",
    "    # s2 and s3 simulations\n",
    "    df_sum = pd.DataFrame()\n",
    "    df_sum['model'] = [m]\n",
    "    for i in ['s2_cveg', 's3_cveg', 's2_csoil', 's3_csoil', 's2_clit', 's3_clit']:\n",
    "        if m + '_' + i in ds_sum.data_vars:\n",
    "            df_sum[i] = [ds_sum[m + '_' + i].values]\n",
    "            df_sum[i] = df_sum[i].astype('float32')\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07a13954-035b-4d7b-9eb2-ed09e7aa19a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dgvms\n",
    "list_dgvm = ['cablepop', 'classic', 'clm', 'dlem', 'ibis', 'isam', 'jsbach', \n",
    "             'jules', 'lpjguess', 'lpjwsl', 'orchidee']\n",
    "# List of dgvms and other data\n",
    "list_m = ['ganzenmueller', 'erb', 'walker', 'mo', 'sanderman030', \n",
    "          'sanderman100', 'sanderman200', * list_dgvm]\n",
    "\n",
    "# Create dataframe with carbon stocks on primary land data of \n",
    "# dgvms, this study, walker, erb, and sanderman\n",
    "df_sum = pd.concat([prep_ds_carbon_sum_luh2res(m) for m in list_m])\n",
    "\n",
    "# Add rows for dgvm mean\n",
    "df_sum_dgvm = df_sum[df_sum.model.isin(list_dgvm)]\n",
    "new_row = ['dgvm_mean', *df_sum_dgvm.iloc[:,1:].mean(axis=0)]\n",
    "df_sum.loc[len(df_sum)] = new_row\n",
    "\n",
    "# Column vegetation deficit\n",
    "df_sum['cveg_d'] = df_sum.s3_cveg - df_sum.s2_cveg\n",
    "# Colum vegetationd deficit in %\n",
    "df_sum['cveg_dp'] = 1-(df_sum.s3_cveg / df_sum.s2_cveg)\n",
    "# Column soil deficit\n",
    "df_sum['csoil_d'] = df_sum.s3_csoil - df_sum.s2_csoil\n",
    "# Column soil deficit in %\n",
    "df_sum['csoil_dp'] =1-( df_sum.s3_csoil / df_sum.s2_csoil)\n",
    "# Select and order relevant columns\n",
    "df_sum = df_sum[['model', 's2_cveg', 's3_cveg', 'cveg_d', 'cveg_dp',\n",
    "                 's2_csoil', 's3_csoil', 'csoil_d', 'csoil_dp']] \\\n",
    "    .reset_index(drop=True) \\\n",
    "    .round(2)\n",
    "\n",
    "# Export\n",
    "df_sum.to_csv(os.path.join(dir05x, 'data_dgvm_global.csv'), index=False)\n",
    "\n",
    "df_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ab8fa6d-8b8d-4245-89f9-74431b851c3d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c56a1e4-02b6-4986-bd1d-f330003a375b",
   "metadata": {},
   "source": [
    "### Calculate based on original resolution (should be the same result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56ab11dc-3efe-42fa-ba4e-6e90ac45bff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=24,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='02:00:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=2)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e5f39-91bb-4b7f-8778-92019eab6639",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_ds_carbon_sum(m):\n",
    "    \n",
    "    \"\"\"Calculate carbon stocks on primary land of dgvm\"\"\"\n",
    "    \n",
    "    # Get data\n",
    "    if m in list_dgvm:\n",
    "        ds = xr.open_dataset(os.path.join(dir05x, m, f'ds_{m}.nc'))\n",
    "        ds_land = xr.open_dataset(os.path.join(dir05x, m, f'ds_{m}_land.nc'))\n",
    "        ds_prim = xr.open_dataset(os.path.join(dir05x, m, f'ds_{m}_prim.nc'))\n",
    "        ds_prim_land = xr.open_dataset(os.path.join(dir05x, m, f'ds_luh2_land_{m}res.nc'))\n",
    "        ds_area = xr.open_dataset(os.path.join(dir05x, m, f'ds_{m}_grid_cell_area.nc'))\n",
    "        da_prim_land = ds_prim_land.land_sea_mask\n",
    "\n",
    "    if m in list_other:\n",
    "        ds = xr.open_zarr(os.path.join(dir05x, m, f'ds_{m}.zarr')) \\\n",
    "            .chunk(dict(lat=5000, lon=5000))\n",
    "        ds_land = xr.open_zarr(os.path.join(dir05x, m, f'ds_{m}_land.zarr')) \\\n",
    "            .chunk(dict(lat=5000, lon=5000))\n",
    "        ds_prim = xr.open_zarr(os.path.join(dir05x, m, f'ds_{m}_prim.zarr')) \\\n",
    "            .chunk(dict(lat=5000, lon=5000))\n",
    "        ds_area = xr.open_zarr(os.path.join(dir05x, m, f'ds_{m}_grid_cell_area.zarr')) \\\n",
    "            .chunk(dict(lat=5000, lon=5000))\n",
    "        da_prim_land = xr.where(ds_prim == ds_prim, 1, 0) \\\n",
    "            .prim_1700.rename('land_sea_mask')\n",
    "\n",
    "    # Create arrays from datasets\n",
    "    da_land = ds_land.land_sea_mask\n",
    "    da_prim = ds_prim.prim_1700\n",
    "    da_area = ds_area.grid_cell_area_ha\n",
    "\n",
    "    # Calculate carbon stocks\n",
    "    ds_sum = (ds * da_land.data * da_prim.data * da_prim_land.data * da_area.data) \\\n",
    "        .sum(['lat', 'lon']) * 0.000000001\n",
    "    \n",
    "    # Create dataframe with carbon stocks of vegetation, soil and litter of\n",
    "    # s2 and s3 simulations\n",
    "    df_sum = pd.DataFrame()\n",
    "    df_sum['model'] = [m]\n",
    "    for i in ['s2_cveg', 's3_cveg', 's2_csoil', 's3_csoil', 's2_clit', \n",
    "              's3_clit']:\n",
    "        if m + '_' + i in ds_sum.data_vars:\n",
    "            df_sum[i] = [ds_sum[m + '_' + i].values]\n",
    "            df_sum[i] = df_sum[i].astype('float32')\n",
    "    return df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9e6b5f-a1e1-4b7a-990c-db2564e89e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of dgvms\n",
    "list_dgvm = ['cablepop', 'classic', 'clm', 'dlem', 'ibis', 'isam', 'jsbach', \n",
    "             'jules', 'lpjguess', 'lpjwsl', 'orchidee']\n",
    "# List of other data\n",
    "list_other = ['pot', 'erb', 'walker', 'mo', 'sanderman030', 'sanderman100',\n",
    "              'sanderman200']\n",
    "# List of dgvms and other data\n",
    "list_m = [*list_other, * list_dgvm]\n",
    "\n",
    "# Create dataframe with carbon stocks on primary land data of \n",
    "# dgvms, this study, walker, erb, and sanderman\n",
    "df_sum = pd.concat([prep_ds_carbon_sum(m) for m in list_m])\n",
    "\n",
    "# Add rows for dgvm mean\n",
    "df_sum_dgvm = df_sum[df_sum.model.isin(list_dgvm)]\n",
    "new_row = ['dgvm_mean', *df_sum_dgvm.iloc[:,1:].mean(axis=0)]\n",
    "df_sum.loc[len(df_sum)] = new_row\n",
    "\n",
    "# Column vegetation deficit\n",
    "df_sum['cveg_d'] = df_sum.s3_cveg - df_sum.s2_cveg\n",
    "# Colum vegetationd deficit in %\n",
    "df_sum['cveg_dp'] = 1-(df_sum.s3_cveg / df_sum.s2_cveg)\n",
    "# Column soil deficit\n",
    "df_sum['csoil_d'] = df_sum.s3_csoil - df_sum.s2_csoil\n",
    "# Column soil deficit in %\n",
    "df_sum['csoil_dp'] =1-( df_sum.s3_csoil / df_sum.s2_csoil)\n",
    "# Column litter deficit\n",
    "df_sum['clit_d'] = df_sum.s3_clit - df_sum.s2_clit\n",
    "# Column litter deficit in %\n",
    "df_sum['clit_dp'] = 1-(df_sum.s3_clit / df_sum.s2_clit)\n",
    "# Select relevant columns\n",
    "df_sum = df_sum[['model', 's2_cveg', 's3_cveg', 'cveg_d', 'cveg_dp', \n",
    "                 's2_csoil', 's3_csoil', 'csoil_d', 'csoil_dp',\n",
    "                 's2_clit', 's3_clit', 'clit_d', 'clit_dp']] \\\n",
    "    .reset_index(drop=True) \\\n",
    "    .round(2)\n",
    "# Export\n",
    "#df_sum.to_csv(os.path.join(dir05x, 'data_dgvm_global.csv'), index=False)\n",
    "\n",
    "df_sum"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
