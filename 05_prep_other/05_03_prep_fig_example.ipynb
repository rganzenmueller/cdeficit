{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "07615cfe-8fe7-418e-9a6b-a9026f80d502",
   "metadata": {},
   "source": [
    "# Prepare data for Figure \"Example\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1814f96b-ac64-4b68-8595-8c5d6290358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_data = '../data/'\n",
    "dir05 = '../paper_deficit/output/05_prep_other/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0b4211e-14dd-4142-a82f-2bbd3b9a2bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import rioxarray\n",
    "import xarray as xr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507ae97c-c2fe-4f5b-a053-d5f4254c446a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3356c91e-c221-4157-8f43-ad0ea104b0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=12,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='02:00:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=3)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5f7c3c-9b26-4bd1-8917-987b07821161",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89356515-2782-4463-bf47-b5038cc020e2",
   "metadata": {},
   "source": [
    "### Walker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd6cccd-451c-41a5-b329-4272a82b45d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get data\n",
    "def open_walker_orig(fstr):\n",
    "    return rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, f'walker2022/{fstr}.tif'),\n",
    "        chunks=dict(y=5000, x=5000))\n",
    "\n",
    "da_walker_agb_pot = open_walker_orig('Base_Pot_AGB_MgCha_500m')\n",
    "da_walker_agb_cur = open_walker_orig('Base_Cur_AGB_MgCha_500m')\n",
    "da_walker_bgb_pot = open_walker_orig('Base_Pot_BGB_MgCha_500m')\n",
    "da_walker_bgb_cur = open_walker_orig('Base_Cur_BGB_MgCha_500m')\n",
    "da_walker_soc_pot = open_walker_orig('Base_Pot_SOC_MgCha_500m')\n",
    "da_walker_soc_cur = open_walker_orig('Base_Cur_SOC_MgCha_500m')\n",
    "\n",
    "# Create agbc_act and agbc_pot arrays\n",
    "da_walker_agbc_pot = \\\n",
    "    (da_walker_agb_pot.where(da_walker_agb_pot != -32768) + \n",
    "     da_walker_bgb_pot.where(da_walker_bgb_pot != -32768).data) \\\n",
    "    .fillna(-32768) \\\n",
    "    .astype('int16')\n",
    "da_walker_agbc_act = \\\n",
    "    (da_walker_agb_cur.where(da_walker_agb_cur != -32768) + \n",
    "     da_walker_bgb_cur.where(da_walker_bgb_cur != -32768).data) \\\n",
    "    .fillna(-32768) \\\n",
    "    .astype('int16')\n",
    "\n",
    "# Create dataset with all data\n",
    "ds_walker = xr.Dataset()\n",
    "ds_walker['walker_cveg_pot'] = da_walker_agbc_pot\n",
    "ds_walker['walker_cveg_act'] = (('band', 'y', 'x'), da_walker_agbc_act.data)\n",
    "ds_walker['walker_csoil_pot'] = (('band', 'y', 'x'), da_walker_soc_pot.data)\n",
    "ds_walker['walker_csoil_act'] = (('band', 'y', 'x'), da_walker_soc_cur.data)\n",
    "\n",
    "# Export dataset\n",
    "#ds_walker.to_zarr(dirx + 'data_eval/examples/ds_temp_walker.zarr', mode='w')\n",
    "# Import dataset\n",
    "#ds_walker = xr.open_zarr(dirx + 'data_eval/examples/ds_temp_walker.zarr')\n",
    "\n",
    "# Reproject\n",
    "for i in list(ds_walker.data_vars):\n",
    "    ds_walker[i] \\\n",
    "        .rio.reproject('epsg:4326') \\\n",
    "        .rio.to_raster(\n",
    "            os.path.join(dir05, f'fig_example/da_temp_{i}.tif'))\n",
    "    \n",
    "# Reprojected tifs to dataset\n",
    "def open_da_temp_x_tif(fstr):\n",
    "    return rioxarray.open_rasterio(\n",
    "        os.path.join(dir05, f'fig_example/da_temp_walker_{fstr}.tif'),\n",
    "        chunks=dict(y=5000, x=5000))\n",
    "\n",
    "ds_walker_reproj = xr.Dataset()\n",
    "for fstr in ['cveg_act', 'cveg_pot', 'csoil_act', 'csoil_pot']:\n",
    "    ds_walker_reproj[fstr] = open_da_temp_x_tif(fstr)\n",
    "\n",
    "# Process and export as zarr\n",
    "ds_walker_reproj \\\n",
    "    .rename(y='lat', x='lon') \\\n",
    "    .squeeze('band') \\\n",
    "    .drop_vars(['band', 'spatial_ref']) \\\n",
    "    .to_zarr(os.path.join(dir05, 'fig_example/ds_walker_preped.zarr'), \n",
    "             mode='w');\n",
    "\n",
    "# Delete intermediate files\n",
    "for i in list(ds_walker.data_vars):\n",
    "    os.remove(os.path.join(dir05, f'fig_example/da_temp_{i}.tif'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c37eb8-130f-47ec-86ce-d96cb5b96b9d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3afd273-82e4-421e-af68-c8142d88d004",
   "metadata": {},
   "source": [
    "### Mo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f74d979-dfb3-4b40-9a6a-aa6294e0f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_mo_data(fstr, pot_act):\n",
    "    \n",
    "    \"\"\" Get and prepare Mo et al. 2023 potential data\"\"\"    \n",
    "    \n",
    "    # Get potential data\n",
    "    fstr_pot = fstr + '_Full_TGB_carbon_density_Map_Merged.tif'\n",
    "    da_pot = rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, f'mo2023/v1_1/{fstr_pot}'),\n",
    "        chunks = dict(y=5000, x=5000))[0]\n",
    "    da_pot = da_pot.where(da_pot != da_pot.attrs['_FillValue'])\n",
    "    \n",
    "    # Get net data\n",
    "    fstr_net = fstr + '_Net_TGB_carbon_density_Map_Merged.tif'\n",
    "    da_net = rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, f'mo2023/v1_1/{fstr_net}'),\n",
    "        chunks = dict(y=5000, x=5000))[0]\n",
    "    da_net = da_pot.where(da_net != da_net.attrs['_FillValue'])    \n",
    "    \n",
    "    # Define potential and calculate actual data arrays\n",
    "    if pot_act == 'pot':\n",
    "        da_out = da_pot\n",
    "    if pot_act == 'act':\n",
    "        da_out = da_pot - da_net.data\n",
    "        \n",
    "    # Return\n",
    "    return da_out \\\n",
    "        .rename(y='lat', x='lon') \\\n",
    "        .drop_vars(['band', 'spatial_ref'])\n",
    "\n",
    "def prep_mo_data_act(fstr):\n",
    "\n",
    "    \"\"\" Get and prepare Mo et al. 2023 present data\"\"\"\n",
    "    \n",
    "    # Get data\n",
    "    fstr_act = fstr + '_Present_TGB_Density_Map_Merged.tif'\n",
    "    da_act = rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, f'mo2023/v1_1/{fstr_act}'),\n",
    "        chunks = dict(y=5000, x=5000))[0]\n",
    "    \n",
    "    # Change nan value\n",
    "    da_act = da_act.where(da_act != da_act.attrs['_FillValue'])\n",
    "    \n",
    "    # Return\n",
    "    return da_act \\\n",
    "        .rename(y='lat', x='lon') \\\n",
    "        .drop_vars(['band', 'spatial_ref'])\n",
    "\n",
    "# Create Dataset with potential and actual data\n",
    "ds_mo = xr.Dataset(dict(lat=prep_mo_data('SD1', 'pot').lat, \n",
    "                        lon=prep_mo_data('SD1', 'pot').lon))\n",
    "\n",
    "ds_mo['act_gsl'] = (('lat', 'lon'), prep_mo_data_act('GS_Max').data)\n",
    "ds_mo['act_gsu'] = (('lat', 'lon'), prep_mo_data_act('GS_Mean').data)\n",
    "ds_mo['act_h'] = (('lat', 'lon'), prep_mo_data_act('HM').data)\n",
    "ds_mo['act_e'] = (('lat', 'lon'), prep_mo_data_act('SD').data)\n",
    "ds_mo['act_w'] = (('lat', 'lon'), prep_mo_data_act('WK').data)\n",
    "\n",
    "ds_mo['pot_gs1l'] = (('lat', 'lon'), prep_mo_data('GS_Mean1', 'pot').data)\n",
    "ds_mo['pot_gs2l'] = (('lat', 'lon'), prep_mo_data('GS_Mean2', 'pot').data)\n",
    "ds_mo['pot_gs1u'] = (('lat', 'lon'), prep_mo_data('GS_Max1', 'pot').data)\n",
    "ds_mo['pot_gs2u'] = (('lat', 'lon'), prep_mo_data('GS_Max2', 'pot').data)\n",
    "ds_mo['pot_h1'] = (('lat', 'lon'), prep_mo_data('HM1', 'pot').data)\n",
    "ds_mo['pot_h2'] = (('lat', 'lon'), prep_mo_data('HM2', 'pot').data)\n",
    "ds_mo['pot_e1'] = (('lat', 'lon'), prep_mo_data('SD1', 'pot').data)\n",
    "ds_mo['pot_e2'] = (('lat', 'lon'), prep_mo_data('SD2', 'pot').data)\n",
    "ds_mo['pot_w1'] = (('lat', 'lon'), prep_mo_data('WK1', 'pot').data)\n",
    "ds_mo['pot_w2'] = (('lat', 'lon'), prep_mo_data('WK2', 'pot').data)\n",
    "\n",
    "\n",
    "# Create arrays with mean of actual and potential\n",
    "da_mo_cveg_act = ds_mo[[i for i in ds_mo.data_vars if 'act' in i]] \\\n",
    "    .to_array(dim='s').mean('s')\n",
    "da_mo_cveg_pot = ds_mo[[i for i in ds_mo.data_vars if 'pot' in i]] \\\n",
    "    .to_array(dim='s').mean('s')\n",
    "\n",
    "# Create dataset with only with actual and potential mean arrays\n",
    "ds_mo_out = xr.Dataset(dict(lat=prep_mo_data('SD1', 'pot').lat, \n",
    "                            lon=prep_mo_data('SD1', 'pot').lon))\n",
    "\n",
    "ds_mo_out = ds_mo_out.assign(mo_cveg_act = da_mo_cveg_act,\n",
    "                             mo_cveg_pot = da_mo_cveg_pot)\n",
    "\n",
    "# Export as zarr\n",
    "ds_mo_out.to_zarr(os.path.join(dir05, 'fig_example/ds_mo_preped.zarr'),\n",
    "              mode='w');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a87b8f66-3016-4e55-8a5a-6a435fe2d920",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "815670d0-4a0c-4aaf-a4b7-28d831176816",
   "metadata": {},
   "source": [
    "### Erb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fc8a2d6-1e96-4dc5-9620-be696fd0f88a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_erb_tif(file):\n",
    "    \n",
    "    \"\"\"Get and prepare erb data\"\"\"\n",
    "    \n",
    "    # Get data\n",
    "    da = rioxarray.open_rasterio(os.path.join(dir_data + f'erb2018/{file}'))\n",
    "    # Set non-land grid cells to nan and rename coordinates\n",
    "    return (da.where(da != da.attrs['_FillValue']) * 0.01)[0] \\\n",
    "        .drop_vars(['band', 'spatial_ref']) \\\n",
    "        .rename(dict(y='lat', x='lon'))\n",
    "\n",
    "# Dataset with actual carbon densities\n",
    "ds_erb_act = xr.Dataset()\n",
    "for i in ['A', 'B', 'C', 'D', 'E', 'F', 'G']:\n",
    "    da = prep_erb_tif(f'ExtDat_Fig3{i}_gcm.tif')\n",
    "    ds_erb_act[f'erb2018_fig3{i.lower()}'] = da\n",
    "\n",
    "# Dataset with potential carbon densities\n",
    "ds_erb_pot = xr.Dataset()\n",
    "for i in ['A', 'B', 'C', 'D', 'E', 'F']:\n",
    "    da = prep_erb_tif(f'ExtDat_Fig4{i}_gcm.tif')\n",
    "    ds_erb_pot[f'erb2018_fig4{i.lower()}'] = da\n",
    "\n",
    "# Calculate mean of actual and potential\n",
    "da_erb_cveg_act = ds_erb_act.to_array().mean('variable')\n",
    "da_erb_cveg_pot = ds_erb_pot.to_array().mean('variable')\n",
    "\n",
    "# Dataset with mean arrays\n",
    "ds_erb_out = xr.Dataset()\n",
    "ds_erb_out = ds_erb_out.assign(erb_cveg_act = da_erb_cveg_act)\n",
    "ds_erb_out = ds_erb_out.assign(erb_cveg_pot = da_erb_cveg_pot)\n",
    "\n",
    "# Export\n",
    "ds_erb_out.to_zarr(os.path.join(dir05, 'fig_example/ds_erb_preped.zarr'),\n",
    "              mode='w');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c7a84-dbc3-4b94-88ed-7469f34d1e23",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2057328-e498-4fee-bc2f-d14b084cc7f9",
   "metadata": {},
   "source": [
    "### Sanderman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0d279da-12cd-432f-ac92-7e7f13a45b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_sand_tif(base_dir, file_name):\n",
    "    \n",
    "    \"\"\"Get and prepare Sanderman et al. 2017 data\"\"\"\n",
    "    # Get data\n",
    "    file_path = os.path.join(base_dir, file_name)\n",
    "    da = rioxarray.open_rasterio(file_path)\n",
    "    # Set non-land grid cells to NaN and rename coordinates\n",
    "    return da.where(da != da.attrs['_FillValue'])[0] \\\n",
    "        .drop_vars(['band', 'spatial_ref']) \\\n",
    "        .rename(dict(y='lat', x='lon'))\n",
    "\n",
    "# Base directory for Sanderman data\n",
    "sanderman_dir = os.path.join(dir_data, 'sanderman2017')\n",
    "\n",
    "# Load datasets\n",
    "da_sand_act = prep_sand_tif(sanderman_dir, 'SOCS_0_30cm_year_2010AD_10km.tif')\n",
    "da_sand_pot = prep_sand_tif(sanderman_dir, 'SOCS_0_30cm_year_NoLU_10km.tif')\n",
    "\n",
    "# Combine into a single dataset\n",
    "ds_sand_out = xr.Dataset({\n",
    "    'sand_soc_act': da_sand_act,\n",
    "    'sand_soc_pot': da_sand_pot,\n",
    "})\n",
    "\n",
    "# Export\n",
    "ds_sand_out.to_zarr(os.path.join(dir05, 'fig_example/ds_sand_preped.zarr'),\n",
    "                   mode='w');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c6679f-1467-4744-8dd1-dcfd072dc848",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f9a377-5194-4552-91fe-3fcd646dcb9e",
   "metadata": {},
   "source": [
    "### Check Walker vs. Sanderman (not in paper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "797aa361-c10e-4cfe-9531-79bdbaa5c4e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import matplotlib.pyplot as plt\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b89c62-df89-4b30-8e01-6dcaf719d3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data = '../data/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d343dc8-bc76-43fd-8a70-98215b88d4e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sanderman actual\n",
    "da_sand_act = rioxarray.open_rasterio(\n",
    "    dir_data + 'sanderman2017/SOCS_0_200cm_year_2010AD_10km.tif', \n",
    "    chunks = dict(y=5000, x=5000))\n",
    "\n",
    "da_sand_act = da_sand_act.rename(y='lat', x='lon')\n",
    "da_sand_act = da_sand_act.where(da_sand_act != da_sand_act.attrs['_FillValue'])\n",
    "\n",
    "# sanderman potential\n",
    "da_sand_pot = rioxarray.open_rasterio(\n",
    "    dir_data + 'sanderman2017/SOCS_0_200cm_year_NoLU_10km.tif', \n",
    "    chunks = dict(y=5000, x=5000))\n",
    "\n",
    "da_sand_pot = da_sand_pot.rename(y='lat', x='lon')\n",
    "da_sand_pot = da_sand_pot.where(da_sand_pot != da_sand_pot.attrs['_FillValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "624d0947-dd87-4b7b-9a48-7fffed7a7d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "#walker actual\n",
    "da_walk_act = rioxarray.open_rasterio(\n",
    "    dir_data + 'walker2022/Base_Cur_SOC_MgCha_500m.tif', \n",
    "    chunks = dict(y=5000, x=5000))\n",
    "\n",
    "da_walk_act = da_walk_act \\\n",
    "    .rio.reproject('epsg:4326') \\\n",
    "    .chunk(dict(y=5000, x=5000)) \\\n",
    "    .rename(y='lat', x='lon')\n",
    "\n",
    "da_walk_act = da_walk_act.where(da_walk_act != da_walk_act.attrs['_FillValue'])\n",
    "\n",
    "# walker potential\n",
    "da_walk_pot = rioxarray.open_rasterio(\n",
    "    dir_data + 'walker2022/Base_Pot_SOC_MgCha_500m.tif', \n",
    "    chunks = dict(y=5000, x=5000))\n",
    "\n",
    "da_walk_pot = da_walk_pot \\\n",
    "    .rio.reproject('epsg:4326') \\\n",
    "    .chunk(dict(y=5000, x=5000)) \\\n",
    "    .rename(y='lat', x='lon')\n",
    "\n",
    "da_walk_pot = da_walk_pot.where(da_walk_pot != da_walk_pot.attrs['_FillValue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d07c478-73ae-478a-9fff-17046caf2f1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to plot walker and sanderman\n",
    "def plot_sand_walk(latmin, latmax, lonmin, lonmax):\n",
    "    da_sand_act_sel = da_sand_act[0] \\\n",
    "        .sel(lat=slice(latmax, latmin), lon=slice(lonmin, lonmax))\n",
    "    da_sand_pot_sel = da_sand_pot[0] \\\n",
    "        .sel(lat=slice(latmax, latmin), lon=slice(lonmin, lonmax))\n",
    "    da_walk_act_sel = da_walk_act[0] \\\n",
    "        .sel(lat=slice(latmax, latmin), lon=slice(lonmin, lonmax))\n",
    "    da_walk_pot_sel = da_walk_pot[0] \\\n",
    "        .sel(lat=slice(latmax, latmin), lon=slice(lonmin, lonmax))\n",
    "\n",
    "    fig, axs = plt.subplots(figsize=(10, 10), ncols=2, nrows=3)\n",
    "    axs = axs.ravel()\n",
    "\n",
    "    da_sand_act_sel.plot.imshow(ax=axs[0])\n",
    "    da_walk_act_sel.plot.imshow(ax=axs[1])\n",
    "\n",
    "    da_sand_pot_sel.plot.imshow(ax=axs[2])\n",
    "    da_walk_pot_sel.plot.imshow(ax=axs[3])\n",
    "\n",
    "    (da_sand_pot_sel - da_sand_act_sel).plot.imshow(ax=axs[4], vmin=0)\n",
    "    (da_walk_pot_sel - da_walk_act_sel).plot.imshow(ax=axs[5], vmin=0)\n",
    "    \n",
    "    plt.tight_layout();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48cbc089-f53c-4961-9ee9-faca3411935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sand_walk(40, 50, 5, 15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e14ba3-4c97-4008-816f-20edaae30e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sand_walk(46, 48, 9, 11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeff3a35-30b2-4cce-997a-3662967d1f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sand_walk(46, 46.25, 10, 10.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31f8a65f-1bc2-4799-9ec2-5236565bd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
