{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14708ca8-fb56-488f-a733-08e53e8fe9a0",
   "metadata": {},
   "source": [
    "# Prepare data for Figure \"DGVM\" - Prepare other data for regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4096e188-3e2e-4aeb-8fc2-25c5bb61e84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, shutil\n",
    "import xarray as xr\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "356bb314-b50b-483e-ad2e-653bf41bf163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data = '../data/'\n",
    "dir04 = '../paper_deficit/output/04_out/'\n",
    "dir05x = '../paper_deficit/output/05_prep_other/fig_dgvm/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5741970b-5764-409d-8a70-9ddb037d2488",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2584256-8cc2-4c93-807e-e4f440e31c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directories for other data if not exists\n",
    "for i in ['luh2', 'pot', 'erb', 'walker', 'mo', 'sanderman030', \n",
    "          'sanderman100', 'sanderman200']:\n",
    "    if not os.path.exists(os.path.join(dir05x, i)):\n",
    "        os.mkdir(os.path.join(dir05x, i))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6253443-98dc-4a1b-9f5e-2d4aec062d6f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c777161-4d2a-4d7f-8f1e-fa278007e2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=12,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='02:00:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=2)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4a71f3-dca9-40bc-b0ac-f65bbe835c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare luh2 data\n",
    "# Get luh2 states file\n",
    "ds_luh2 = xr.open_dataset(os.path.join(dir_data, 'luh2_v2h/states.nc'),\n",
    "                          chunks=dict(time=100),\n",
    "                          decode_times=False)\n",
    "\n",
    "# Adjust time \n",
    "ds_luh2['time'] = ds_luh2.time.data.astype('int') + 850\n",
    "# Select primary forest and non-forest in 1700 and export\n",
    "(ds_luh2.primf + ds_luh2.primn) \\\n",
    "    .sel(time=1700) \\\n",
    "    .drop_vars('time') \\\n",
    "    .to_dataset(name='prim_1700') \\\n",
    "    .to_netcdf(os.path.join(dir05x, 'luh2/ds_luh2_prim_1700.nc'), mode='w')\n",
    "\n",
    "# Prepare land-sea mask and export\n",
    "xr.where(ds_luh2 == ds_luh2, 1, 0).primf.sel(time=1700) \\\n",
    "    .astype('float64') \\\n",
    "    .drop_vars('time') \\\n",
    "    .rename('land_sea_mask') \\\n",
    "    .to_netcdf(os.path.join(dir05x, 'luh2/ds_luh2_land.nc'), mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f51ca0-5576-4d4d-ad1b-d7408260a3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare predicted carbon density data\n",
    "ds_agbc = xr.open_dataset(os.path.join(dir04, 'agbc.nc')) \\\n",
    "    .chunk(dict(lat=5000, lon=5000))\n",
    "ds_bgbc = xr.open_dataset(os.path.join(dir04, 'bgbc.nc')) \\\n",
    "    .chunk(dict(lat=5000, lon=5000))\n",
    "ds_soc = xr.open_dataset(os.path.join(dir04, 'soc.nc')) \\\n",
    "    .chunk(dict(lat=5000, lon=5000))\n",
    "\n",
    "# Create dataset with relevant variables\n",
    "ds_pot = xr.Dataset(\n",
    "    dict(pot_s2_cveg = ds_agbc.agbc_max_prim + ds_bgbc.bgbc_max_prim,\n",
    "         pot_s3_cveg = ds_agbc.agbc_max_act + ds_bgbc.bgbc_max_act,\n",
    "         pot_s2_csoil = ds_soc.soc_mean_prim,\n",
    "         pot_s3_csoil = ds_soc.soc_mean_act)\n",
    ")\n",
    "\n",
    "# Remove variable attributes (needed for regridding)\n",
    "for i in list(ds_pot.data_vars):\n",
    "    ds_pot[i].attrs = {}\n",
    "\n",
    "# Export\n",
    "ds_pot.to_zarr(os.path.join(dir05x + 'pot/ds_pot.zarr'), mode='w')\n",
    "\n",
    "# Create and export land-sea mask\n",
    "xr.where(ds_pot.pot_s2_cveg == ds_pot.pot_s2_cveg, 1, 0) \\\n",
    "    .rename('land_sea_mask') \\\n",
    "    .to_zarr(os.path.join(dir05x + 'pot/ds_pot_land.zarr'), mode='w');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5a2ac04-4553-4d2d-9b17-82c0b6072048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare erb data\n",
    "# Create dataset with erb maps as variabales\n",
    "ds_erb = xr.Dataset()\n",
    "\n",
    "for i in [i for i in os.listdir(os.path.join(dir_data, 'erb2018')) \n",
    "          if i.endswith('.tif')]:\n",
    "    # Get data and rename coordintaes\n",
    "    da = rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, 'erb2018', \n",
    "                     f'ExtDat_Fig{i[10:11]}{i[11:12]}_gcm.tif'), \n",
    "        chunks=True) \\\n",
    "        .rename(y='lat', x='lon') \\\n",
    "        .squeeze('band') \\\n",
    "        .drop_vars(['band', 'spatial_ref'])\n",
    "    # Add map as variable to dataset\n",
    "    ds_erb['fig' + i[10:11] + '_' + i[11:12].lower()] =  \\\n",
    "        da.where(da != da.attrs['_FillValue']) * 0.01\n",
    "\n",
    "# Mean of erb actual vegetation carbon\n",
    "da_erb_act = ds_erb[[i for i in ds_erb.data_vars if i.startswith('fig3')]] \\\n",
    "    .to_array() \\\n",
    "    .mean('variable')\n",
    "\n",
    "# Mean of erb potential vegetation carbon\n",
    "da_erb_pot = ds_erb[[i for i in ds_erb.data_vars if i.startswith('fig4')]] \\\n",
    "    .to_array() \\\n",
    "    .mean('variable')\n",
    "\n",
    "# Create dataset with mean values\n",
    "ds_erb2 = xr.Dataset()\n",
    "ds_erb2['erb_s2_cveg'] = da_erb_pot\n",
    "ds_erb2['erb_s3_cveg'] = da_erb_act\n",
    "\n",
    "# Export\n",
    "ds_erb2.to_zarr(os.path.join(dir05x, 'erb', 'ds_erb.zarr'), mode='w')\n",
    "\n",
    "# Create and export land-sea mask\n",
    "xr.where(ds_erb2.erb_s2_cveg == ds_erb2.erb_s2_cveg, 1, 0) \\\n",
    "    .rename('land_sea_mask') \\\n",
    "    .to_zarr(os.path.join(dir05x, 'erb', 'ds_erb_land.zarr'), mode='w');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33ea125-b3bb-4701-a728-6690efd67dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare sanderman data\n",
    "# Look through data of different soild depths\n",
    "for case in ['sanderman030', 'sanderman100', 'sanderman200']:\n",
    "    # define depth based on case name\n",
    "    if case == 'sanderman030':\n",
    "        fstr = '0_30cm'\n",
    "    if case == 'sanderman100':\n",
    "        fstr = '0_100cm'\n",
    "    if case == 'sanderman200':\n",
    "        fstr = '0_200cm'\n",
    "\n",
    "    # Get data\n",
    "    da_sand_pot = rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, 'sanderman2017', \n",
    "                     f'SOCS_{fstr}_year_NoLU_10km.tif'),\n",
    "        chunks=dict(y=5000, x=5000))\n",
    "\n",
    "    da_sand_cur = rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, 'sanderman2017', \n",
    "                     f'SOCS_{fstr}_year_2010AD_10km.tif'),\n",
    "                     chunks=dict(y=5000, x=5000))\n",
    "    # Create dataset with the two arrays\n",
    "    ds_sand = xr.Dataset()\n",
    "    ds_sand[case + '_s2_csoil'] = da_sand_pot\n",
    "    ds_sand[case + '_s3_csoil'] = da_sand_cur\n",
    "    # rename coordinates and export\n",
    "    ds_sand.rename(y='lat', x='lon') \\\n",
    "        .squeeze('band') \\\n",
    "        .drop_vars(['band', 'spatial_ref']) \\\n",
    "        .to_zarr(os.path.join(dir05x, case, f'ds_{case}.zarr'), mode='w')\n",
    "    \n",
    "# Create and export land-sea mask\n",
    "for case in ['sanderman030', 'sanderman100', 'sanderman200']:\n",
    "    \n",
    "    ds_sand2 = xr.open_zarr(os.path.join(dir05x, case, f'ds_{case}.zarr'))\n",
    "\n",
    "    xr.where(ds_sand2[case + '_s2_csoil'] == \n",
    "             ds_sand2[case + '_s2_csoil'], 1, 0) \\\n",
    "        .rename('land_sea_mask') \\\n",
    "        .to_zarr(os.path.join(dir05x, case, f'ds_{case}_land.zarr'), \n",
    "                 mode='w');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda5c814-ea7c-4f2f-8261-9eec1b89642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare walker data\n",
    "# Get data\n",
    "def read_walker(fstr):\n",
    "    \"\"\"Get walker data\"\"\"\n",
    "    return rioxarray.open_rasterio(os.path.join(dir_data, 'walker2022', fstr), \n",
    "                                   chunks=dict(y=5000, x=5000))\n",
    "\n",
    "da_walker_agb_pot = read_walker('Base_Pot_AGB_MgCha_500m.tif')\n",
    "da_walker_agb_cur = read_walker('Base_Cur_AGB_MgCha_500m.tif')\n",
    "da_walker_bgb_pot = read_walker('Base_Pot_BGB_MgCha_500m.tif')\n",
    "da_walker_bgb_cur = read_walker('Base_Cur_BGB_MgCha_500m.tif')\n",
    "da_walker_soc_pot = read_walker('Base_Pot_SOC_MgCha_500m.tif')\n",
    "da_walker_soc_cur = read_walker('Base_Cur_SOC_MgCha_500m.tif')\n",
    "\n",
    "# Create dataset with walker maps as variables\n",
    "ds_walker = xr.Dataset(dict(band=da_walker_agb_pot.band, \n",
    "                            y=da_walker_agb_pot.y, \n",
    "                            x=da_walker_agb_pot.x))\n",
    "ds_walker['walker_s2_cveg'] = (('band', 'y', 'x'), \n",
    "                        da_walker_agb_pot.where(da_walker_agb_pot != -32768).data + \n",
    "                        da_walker_bgb_pot.where(da_walker_bgb_pot != -32768).data)\n",
    "ds_walker['walker_s2_cveg'] = ds_walker['walker_s2_cveg'].fillna(-32768).astype('int16')\n",
    "\n",
    "ds_walker['walker_s3_cveg'] = (('band', 'y', 'x'), \n",
    "                        da_walker_agb_cur.where(da_walker_agb_cur != -32768).data + \n",
    "                        da_walker_bgb_cur.where(da_walker_bgb_cur != -32768).data)\n",
    "ds_walker['walker_s3_cveg'] = ds_walker['walker_s3_cveg'].fillna(-32768).astype('int16')\n",
    "\n",
    "ds_walker['walker_s2_csoil'] = (('band', 'y', 'x'), da_walker_soc_pot.data)\n",
    "ds_walker['walker_s3_csoil'] = (('band', 'y', 'x'), da_walker_soc_cur.data)\n",
    "\n",
    "# Export\n",
    "ds_walker.to_zarr(os.path.join(dir05x, 'walker', 'walker_temp.zarr'), mode='w')\n",
    "\n",
    "    \n",
    "# Get prepared walker dataset\n",
    "ds_walker = xr.open_zarr(os.path.join(dir05x, 'walker', 'walker_temp.zarr'))\n",
    "\n",
    "# Reproject variable of prepared walker dataset\n",
    "def reproject_walker(fstr):\n",
    "    \"\"\"Reproject variable of prepared walker dataset\"\"\"\n",
    "    ds_walker[fstr] \\\n",
    "    .rio.reproject('epsg:4326') \\\n",
    "    .rename(y='lat', x='lon') \\\n",
    "    .squeeze('band') \\\n",
    "    .drop_vars(['band', 'spatial_ref']) \\\n",
    "    .to_dataset(name=fstr) \\\n",
    "    .to_zarr(os.path.join(dir05x, 'walker', f'walker_temp_{fstr}.zarr'),\n",
    "             mode='w')\n",
    "\n",
    "for i in ds_walker.data_vars:\n",
    "    reproject_walker(i)\n",
    "\n",
    "# Combine reprojected variales in dataset and export\n",
    "ds = xr.open_mfdataset(os.path.join(dir05x, 'walker', 'walker_temp_*.zarr'), \n",
    "                       engine='zarr')\n",
    "\n",
    "for var in ds:\n",
    "    del ds[var].encoding['chunks']\n",
    "    \n",
    "ds.chunk(dict(lat=5000, lon=5000)) \\\n",
    "    .to_zarr(os.path.join(dir05x, 'walker', 'ds_walker.zarr'),  mode=\"w\")\n",
    "\n",
    "# Create and export land-sea mask\n",
    "ds_walker2 = xr.open_zarr(os.path.join(dir05x, 'walker', 'ds_walker.zarr'))\n",
    "\n",
    "xr.where(ds_walker2.walker_s2_cveg == ds_walker2.walker_s2_cveg, 1, 0) \\\n",
    "    .rename('land_sea_mask') \\\n",
    "    .to_zarr(os.path.join(dir05x, 'walker', 'ds_walker_land.zarr'), mode='w')\n",
    "\n",
    "# Delete temporary files\n",
    "for f in [i for i in os.listdir(os.path.join(dir05x, 'walker')) \n",
    "          if i[:6] == 'walker']:\n",
    "    shutil.rmtree(os.path.join(dir05x, 'walker', f));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d1497f-aa3e-4580-9f5a-a4f123d7c214",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mo\n",
    "def prep_mo(act_pot, fstr):\n",
    "\n",
    "    \"\"\"Get Mo data\"\"\"\n",
    "    \n",
    "    if act_pot == 'pot':\n",
    "        path_fstr = os.path.join(\n",
    "        dir_data, f'mo2023/v1_1/{fstr}_Full_TGB_carbon_density_Map_Merged.tif')\n",
    "    if act_pot == 'act':\n",
    "        path_fstr = os.path.join(\n",
    "        dir_data, f'mo2023/v1_1/{fstr}_Present_TGB_Density_Map_Merged.tif')\n",
    "\n",
    "    \n",
    "    da = rioxarray.open_rasterio(path_fstr, chunks = dict(y=5000, x=5000))[0]\n",
    "    da = da.where(da != da.attrs['_FillValue'])\n",
    "    return da.rename(y='lat', x='lon').drop_vars(['band', 'spatial_ref'])\n",
    "\n",
    "# Create Dataset with Mo data\n",
    "ds_mo = xr.Dataset(dict(lat=prep_mo('act', 'SD').lat, \n",
    "                        lon=prep_mo('act', 'SD').lon))\n",
    "\n",
    "ds_mo['act_gsl'] = (('lat', 'lon'), prep_mo('act', 'GS_Max').data)\n",
    "ds_mo['act_gsu'] = (('lat', 'lon'), prep_mo('act', 'GS_Mean').data)\n",
    "ds_mo['act_sdh'] = (('lat', 'lon'), prep_mo('act', 'HM').data)\n",
    "ds_mo['act_sde'] = (('lat', 'lon'), prep_mo('act', 'SD').data)\n",
    "ds_mo['act_sdw'] = (('lat', 'lon'), prep_mo('act', 'WK').data)\n",
    "\n",
    "ds_mo['pot_gs1l'] = (('lat', 'lon'), prep_mo('pot', 'GS_Mean1').data)\n",
    "ds_mo['pot_gs2l'] = (('lat', 'lon'), prep_mo('pot', 'GS_Mean2').data)\n",
    "ds_mo['pot_gs1u'] = (('lat', 'lon'), prep_mo('pot', 'GS_Max1').data)\n",
    "ds_mo['pot_gs2u'] = (('lat', 'lon'), prep_mo('pot', 'GS_Max2').data)\n",
    "ds_mo['pot_sd1h'] = (('lat', 'lon'), prep_mo('pot', 'HM1').data)\n",
    "ds_mo['pot_sd2h'] = (('lat', 'lon'), prep_mo('pot', 'HM2').data)\n",
    "ds_mo['pot_sd1e'] = (('lat', 'lon'), prep_mo('pot', 'SD1').data)\n",
    "ds_mo['pot_sd2e'] = (('lat', 'lon'), prep_mo('pot', 'SD2').data)\n",
    "ds_mo['pot_sd1w'] = (('lat', 'lon'), prep_mo('pot', 'WK1').data)\n",
    "ds_mo['pot_sd2w'] = (('lat', 'lon'), prep_mo('pot', 'WK2').data)\n",
    "\n",
    "# Dataset with mean actual and potential mo values\n",
    "ds_mo2 = xr.Dataset()\n",
    "ds_mo2['mo_s2_cveg'] = ds_mo[[i for i in ds_mo.data_vars if 'pot' in i]] \\\n",
    "    .to_array(dim='s').mean('s')\n",
    "ds_mo2['mo_s3_cveg'] = ds_mo[[i for i in ds_mo.data_vars if 'act' in i]] \\\n",
    "    .to_array(dim='s').mean('s')\n",
    "\n",
    "# Export\n",
    "ds_mo2.to_zarr(os.path.join(dir05x, 'mo', 'ds_mo.zarr'), mode='w');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe48df1-cfa1-4574-b594-01761e2b7a2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mo land sea mask \n",
    "# Land sea differences between actual, potential, open-water file\n",
    "def prep_mo_land(f_in, f_out):\n",
    "    \n",
    "    \"\"\"Prepare Mo land sea masks\"\"\"\n",
    "    \n",
    "    da_land_x = rioxarray.open_rasterio(\n",
    "        os.path.join(dir_data, f'mo2023/v1_1/{f_in}.tif'),\n",
    "        chunks = dict(y=5000, x=5000))[0]\n",
    "\n",
    "    if f_out in ['ds_mo_land_act', 'ds_mo_land_pot']:\n",
    "        v_na = da_land_x.attrs['_FillValue']\n",
    "        da_land = xr.where(da_land_x != v_na, 1., 0.)\n",
    "    if f_out == 'ds_mo_land':\n",
    "        da_land = da_land_x\n",
    "    ds_land = xr.Dataset(dict(lat=ds_mo.lat, lon=ds_mo.lon))\n",
    "    ds_land['land_sea_mask'] = (('lat', 'lon'), da_land.data.astype('float32'))\n",
    "    ds_land.to_zarr(\n",
    "        os.path.join(dir05x, 'mo', f'{f_out}.zarr'), mode='w')\n",
    "\n",
    "\n",
    "prep_mo_land('SD_Present_TGB_Density_Map_Merged', 'ds_mo_land_act')\n",
    "prep_mo_land('SD1_Full_TGB_carbon_density_Map_Merged', 'ds_mo_land_pot')\n",
    "prep_mo_land('Open_Water_mask_Map', 'ds_mo_land');"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983a80f0-cf32-446f-9943-4ead91b8029d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cad3c91-bb4f-4d88-8e21-e70e003cf36a",
   "metadata": {},
   "source": [
    "### Check Mo land masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5447c57-fd9a-4add-ace3-9d343c12bc63",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b31f6d-3d35-47e0-8924-a5899b59d251",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 5), ncols=3, nrows=1)\n",
    "xr.open_zarr(os.path.join(dir05x, 'mo/ds_mo_land.zarr')) \\\n",
    "    .land_sea_mask.plot.imshow(ax=axs[0])\n",
    "xr.open_zarr(os.path.join(dir05x, 'mo/ds_mo_land_act.zarr')) \\\n",
    "    .land_sea_mask.plot.imshow(ax=axs[1])\n",
    "xr.open_zarr(os.path.join(dir05x, 'mo/ds_mo_land_pot.zarr')) \\\n",
    "    .land_sea_mask.plot.imshow(ax=axs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4abd39b1-625f-4701-b544-aaf8fdf4baf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(figsize=(20, 5), ncols=3, nrows=1)\n",
    "\n",
    "xr.open_zarr(os.path.join(dir05x, 'mo/ds_mo_land.zarr')) \\\n",
    "    .sel(lat=slice(60, 40), lon=slice(0, 20)) \\\n",
    "    .land_sea_mask.plot.imshow(ax=axs[0], add_colorbar=False)\n",
    "xr.open_zarr(os.path.join(dir05x, 'mo/ds_mo_land_act.zarr')) \\\n",
    "    .sel(lat=slice(60, 40), lon=slice(0, 20)) \\\n",
    "    .land_sea_mask.plot.imshow(ax=axs[1], add_colorbar=False)\n",
    "xr.open_zarr(os.path.join(dir05x, 'mo/ds_mo_land_pot.zarr')) \\\n",
    "    .sel(lat=slice(60, 40), lon=slice(0, 20)) \\\n",
    "    .land_sea_mask.plot.imshow(ax=axs[2], add_colorbar=False)\n",
    "\n",
    "axs[0].set_title('open_water_mask')\n",
    "axs[1].set_title('from actual carbon file')\n",
    "axs[2].set_title('from potential carbon file')\n",
    "\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe197ce9-68cd-4bf7-b470-6b09569d8e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
