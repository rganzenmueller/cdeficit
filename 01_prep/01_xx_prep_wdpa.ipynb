{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84a7dc9d-9254-4e14-91a7-c8944b4c6b11",
   "metadata": {},
   "source": [
    "# Prepare protected areas data (WDPA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c888b81-6cd8-4bc4-88a8-ca313ff4d2b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os, time, shutil, rasterio, rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa34d6ac-41e3-496b-b317-4a10641f16b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data =  '../data/'\n",
    "dir01 = '../paper_deficit/output/01_prep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2c40a3-eb0d-4c0d-a004-719162a171d8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08832525-62e8-4196-aa9c-b60173753ef5",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23fe0531-0fdf-4c31-ae12-3e8a50832dde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WDPA categories\n",
    "# Ia - strict nature reserve.\n",
    "# Ib - wilderness area.\n",
    "# II - national park.\n",
    "# III - natural monument or feature.\n",
    "# IV - habitat or species management area.\n",
    "# V - protected landscape or seascape.\n",
    "# VI - protected area with sustainable use of natural resources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f47d362c-297e-4577-97a7-9074bc40207f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_wdpa():\n",
    "    \"\"\"\n",
    "    Prepare and export World Database on Protected Areas (WDPA) data for selected categories and statuses.    \n",
    "    Reprojects WDPA shapefiles, filters by category and status, and exports as rasters.\n",
    "    \"\"\"\n",
    "\n",
    "    \n",
    "    # Path to reference raster and WDPA shapefiles\n",
    "    rst_path = os.path.join(dir_data, 'worldclim/wc2.1_30s_elev/wc2.1_30s_elev.tif')\n",
    "    wdpa_base = os.path.join(dir_data, 'wdpa/WDPA_Nov2022_Public_shp')\n",
    "\n",
    "    # Read reference raster metadata\n",
    "    with rasterio.open(rst_path) as rst:\n",
    "        meta = rst.meta.copy()\n",
    "        meta.update(compress='lzw')\n",
    "    \n",
    "    # Load and merge shapefiles\n",
    "    shapefiles = [os.path.join(wdpa_base,f'WDPA_Nov2022_Public_shp_{i}/WDPA_Nov2022_Public_shp-polygons.shp')\n",
    "                  for i in range(3)]\n",
    "    shp = pd.concat([gpd.read_file(shp_file) for shp_file in shapefiles]) \\\n",
    "        .to_crs(\"EPSG:4326\")\n",
    "    \n",
    "    # Define relevant categories and statuses\n",
    "    categories = ['Ia', 'Ib', 'II', 'III', 'IV', 'V', 'VI']\n",
    "    statuses = ['Adopted', 'Designated', 'Established', 'Inscribed']\n",
    "    \n",
    "    # Function to convert GeoDataFrame to raster\n",
    "    def gpd_to_tif(shp, out_fn):\n",
    "        with rasterio.open(out_fn, 'w+', **meta) as out:\n",
    "            out_arr = out.read(1)\n",
    "            shapes = ((geom, value) for geom, value in zip(shp.geometry, \n",
    "                                                           shp['value']))\n",
    "            burned = rasterio.features.rasterize(shapes=shapes, \n",
    "                                                 fill=0,\n",
    "                                                 out=out_arr, \n",
    "                                                 transform=out.transform)\n",
    "            out.write_band(1, burned)\n",
    "    \n",
    "    # Process and export each category\n",
    "    for cat in categories:\n",
    "        shp_sel = shp[\n",
    "        (shp['IUCN_CAT'] == cat) & (shp['STATUS'].isin(statuses))\n",
    "        ][['geometry', 'STATUS_YR']]\n",
    "        shp_sel = shp_sel.assign(value=1)\n",
    "        \n",
    "        # Export raster for each category\n",
    "        output_file = os.path.join(dir01, f'wdpa_{cat.lower()}.tif')\n",
    "        gpd_to_tif(shp_sel, output_file)\n",
    "        \n",
    "        # Post-process raster\n",
    "        # Read data\n",
    "        da_sel = rioxarray.open_rasterio(output_file, \n",
    "                                         chunks={'y': 5000, 'x': 5000})\n",
    "        # Select grid cells that are 100% the selected category\n",
    "        da_sel = xr.where(da_sel == 1, 1, 0).astype('int8')\n",
    "        # Select lat between 80 and -60\n",
    "        da_sel = da_sel.sel(y=slice(80, -60))\n",
    "        # Adjust attributes\n",
    "        da_sel.attrs['long_name'] = f'wdpa_{cat.lower()}'\n",
    "        # export\n",
    "        da_sel.rio.to_raster(output_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89797849-3bcd-47f0-b0b3-34dcfe8ba93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%time prep_wdpa()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a5b8793-ef03-4ad7-b9f9-0ea0b5c66335",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ff63756-94a8-4b91-b36c-473e59975324",
   "metadata": {},
   "source": [
    "### Post-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f7c33c-c01a-401e-9eb6-d2d7bc363e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(da_var, var, dir_out):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the specified variable's dataset using the nearest valid \n",
    "    data, applies a land mask, and exports the result to a new Zarr dataset.\n",
    "\n",
    "    Args:\n",
    "        var (str): Name of the variable to process (e.g., 'temperature', 'precipitation').\n",
    "        dir_out (str): Directory where prepared data is stored and the filled dataset will be exported.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def fill_nans_array(data, invalid):\n",
    "        \"\"\"\n",
    "        Replace invalid (NaN) data cells by the value of the nearest valid data \n",
    "        cell.\n",
    "        \"\"\"\n",
    "        ind = ndimage.distance_transform_edt(invalid,\n",
    "                                             return_distances=False,\n",
    "                                             return_indices=True)\n",
    "        return data[tuple(ind)]\n",
    "\n",
    "    # Paths for input and output\n",
    "    land_mask_path = os.path.join(dir_out, 'ds_prep_copernicus_land_mask.zarr')\n",
    "    output_path = os.path.join(dir_out, f'ds_prep_{var}.zarr')\n",
    "\n",
    "    # Read land mask data\n",
    "    da_land = xr.open_zarr(land_mask_path) \\\n",
    "                .chunk(dict(lat=5000, lon=5000)) \\\n",
    "                .copernicus_land_mask \\\n",
    "                .compute()\n",
    "\n",
    "    # Fill nan using function fill_nans_array\n",
    "    # If there are no NaNs, skip filling process\n",
    "    if not da_var.isnull().any():\n",
    "        da_fill = da_var.values  # No filling required\n",
    "    else:\n",
    "        da_fill = fill_nans_array(da_var.values, da_var.isnull().values)\n",
    "\n",
    "    # Create a new Dataset with filled data\n",
    "    ds_filled = xr.Dataset(dict(lat = da_var.lat, lon=da_var.lon))\n",
    "    ds_filled[var] = (('lat', 'lon'), da_fill)\n",
    "\n",
    "    # Apply land mask to the filled data\n",
    "    ds_filled = ds_filled.where(da_land)\n",
    "\n",
    "    # Export the filled dataset to Zarr format\n",
    "    ds_filled.chunk(dict(lat=5000, lon=5000)) \\\n",
    "             .to_zarr(output_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6228dbb5-98aa-43fb-94f5-7a7538a6e29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['wdpa_ia', 'wdpa_ib', 'wdpa_ii', 'wdpa_iii', 'wdpa_iv', 'wdpa_v',\n",
    "          'wdpa_vi']:\n",
    "    # Read data\n",
    "    da_var = rioxarray.open_rasterio(dir01 + i + '.tif')[0] \\\n",
    "        .rename(dict(y='lat', x='lon'))\n",
    "    # Fill nans with nearest neighbour if there are nans\n",
    "    %time fill_nans(da_var, i, dir01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abf5d36f-4fda-4c2b-8ffd-2e5a7e8d9983",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba64130a-3474-4b2e-9ef2-024e97c5c943",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d792b829-fd9b-4393-bbbc-0db433b0f86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "for i in ['wdpa_ia', 'wdpa_ib', 'wdpa_ii', 'wdpa_iii', 'wdpa_iv', 'wdpa_v',\n",
    "          'wdpa_vi']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a10e946-9091-4f42-808f-0f4274860783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_wdpa():\n",
    "    shp0 = gpd.read_file(dir_data + 'wdpa/WDPA_Nov2022_Public_shp/' + \n",
    "                            'WDPA_Nov2022_Public_shp_0/' + \n",
    "                            'WDPA_Nov2022_Public_shp-polygons.shp')\n",
    "\n",
    "    shp1 = gpd.read_file(dir_data + 'wdpa/WDPA_Nov2022_Public_shp/' + \n",
    "                            'WDPA_Nov2022_Public_shp_1/' + \n",
    "                            'WDPA_Nov2022_Public_shp-polygons.shp')\n",
    "\n",
    "    shp2 = gpd.read_file(dir_data + 'wdpa/WDPA_Nov2022_Public_shp/' + \n",
    "                            'WDPA_Nov2022_Public_shp_2/' + \n",
    "                            'WDPA_Nov2022_Public_shp-polygons.shp')\n",
    "\n",
    "    # merge shape files\n",
    "    shp = pd.concat([shp0, shp1, shp2])\n",
    "\n",
    "    # select highest protection categories\n",
    "    shp_cat = shp[shp['IUCN_CAT']\n",
    "                  .isin(['Ia', 'Ib', 'II', 'III', 'IV', 'V', 'VI'])]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20, 10), ncols=1, nrows=1, dpi=300)\n",
    "\n",
    "    xr.open_mfdataset(dir01 + 'ds_prep_wdpa_*.zarr', engine='zarr') \\\n",
    "        .to_array('x') \\\n",
    "        .sum('x') \\\n",
    "        .sel(lat=slice(50, 20), lon=slice(-120, -70)) \\\n",
    "        .plot.imshow(ax=ax, vmin=0, vmax=1)\n",
    "\n",
    "    shp_cat.plot(ax=ax, edgecolor='red', color='none')\n",
    "\n",
    "    ax.set_ylim(20, 50)\n",
    "    ax.set_xlim(-120, -70);\n",
    "    \n",
    "\n",
    "check_wdpa()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
