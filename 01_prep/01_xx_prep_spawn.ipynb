{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "86cdd539-ff0d-4608-96c7-0059101b61bc",
   "metadata": {},
   "source": [
    "# Prepare above and belowground biomass carbon data (Spawn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df21d6b8-f7e9-4ec1-87da-e3b62f9d7586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, time, shutil, rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f95339-ad46-4661-8e33-c0a755da6292",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data =  '../data/'\n",
    "dir01 = '../paper_deficit/output/01_prep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66284070-63a3-46b0-9321-9af5c97e9473",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c2e27c9-39ff-4362-b00c-01ad2524425c",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0053de1-acc8-45e9-813b-5fdfa6820e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=24,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='00:30:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=5)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6c941f-2f90-4098-bab8-4b70755f94f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_spawn():\n",
    "    \"\"\"Prepare spawn data\"\"\"\n",
    "    \n",
    "    def spawn_load(file):\n",
    "        '''Load spawn files'''\n",
    "\n",
    "        return  rioxarray.open_rasterio(dir_data + 'spawn2020/' + file, \n",
    "                                        chunks=dict(y=5000, x=5000))\n",
    "\n",
    "    # load spawn data and extract area\n",
    "    da_biom_agbc = spawn_load('aboveground_biomass_carbon_2010.tif')\n",
    "    da_biom_bgbc = spawn_load('belowground_biomass_carbon_2010.tif')\n",
    "    da_biom_agbcunc = spawn_load(\n",
    "        'aboveground_biomass_carbon_2010_uncertainty.tif')\n",
    "    da_biom_bgbcunc = spawn_load(\n",
    "        'belowground_biomass_carbon_2010_uncertainty.tif')\n",
    "    \n",
    "    # *0.1 for convertion to MgC/ha \n",
    "    ds = xr.Dataset(dict(band=da_biom_agbc.band, \n",
    "                         y=da_biom_agbc.y, \n",
    "                         x=da_biom_agbc.x))\n",
    "    ds['spawn_agbc'] = (('band', 'y', 'x'), da_biom_agbc.data * 0.1)\n",
    "    ds['spawn_bgbc'] = (('band', 'y', 'x'), da_biom_bgbc.data * 0.1)\n",
    "    ds['spawn_agbcunc'] = (('band', 'y', 'x'), da_biom_agbcunc.data * 0.1)\n",
    "    ds['spawn_bgbcunc'] = (('band', 'y', 'x'), da_biom_bgbcunc.data * 0.1)\n",
    "    ds = ds.persist()\n",
    "\n",
    "    # change dtype\n",
    "    ds = ds.astype(np.float32)\n",
    "    \n",
    "    # add attributes\n",
    "    ds.attrs = da_biom_agbc.attrs\n",
    "    #export\n",
    "    for i in ds.data_vars:\n",
    "        ds[i].rio.to_raster(dir01 + i + '.tif')\n",
    "        \n",
    "\n",
    "%time prep_spawn()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51d5dc35-4c2a-4d67-9bd3-3d8143a118c2",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea1847b7-de41-4850-92a5-8c57121a99f0",
   "metadata": {},
   "source": [
    "### Regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e24fb0aa-d1ea-4b4b-9d81-132556c5cdf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regridding function\n",
    "from regrid_high_res_v1_01 import regrid_high_res, prep_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "173c6c99-061a-4c19-8d0c-7702465b2adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_da(f_source, dir_target, dir_source, dir_out, \n",
    "              size_tiles, fill_value=None, olap=1):  \n",
    "    \"\"\"Regrid large xarray dataarrays.\n",
    "\n",
    "    Args:\n",
    "        f_source (str): The filename (without extension) of the source .tif file to be regridded.\n",
    "        dir_target (str): Directory containing target grid .tif file.\n",
    "        dir_source (str): Directory containing the the source  .tif file.\n",
    "        dir_out (str): Directory to store the output and intermediate files.\n",
    "        size_tiles (int): Size of the regridding tiles in degrees.\n",
    "        fill_value (float, optional): Fill value to use in the regridding process. Defaults to None.\n",
    "        olap (int, optional): Overlap size in degrees for regridding tiles. Defaults to 1.\n",
    "        \n",
    "    Returns:\n",
    "        xarray.Dataset: The combined dataset after regridding.\n",
    "    \"\"\"\n",
    "    # Prepare the target and source data arrays from TIFF files\n",
    "    da_target = prep_tif(dir_target + 'target_grid.tif', 'target_grid')\n",
    "    da_source = prep_tif(dir_source + f_source + '.tif', f_source)\n",
    "    # Regridd source array to target grid\n",
    "    regrid_high_res(da_target, da_source, dir_out,\n",
    "                    account='bm0891', partition='shared',\n",
    "                    size_tiles=size_tiles, olap=olap, fill_value = fill_value,\n",
    "                    type_export='zarr', del_interm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd67913-88fc-4ea5-939d-d4aacaa54d6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regridding\n",
    "for i in ['spawn_agbc', 'spawn_bgbc', 'spawn_agbcunc', 'spawn_bgbcunc']:\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 20, np.nan, 0.1)\n",
    "# Takes about 8-12min for one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f986711b-3b63-47c6-9ddb-4c55d3533f72",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c32c56-5964-473a-b984-5a1c34e6a9b2",
   "metadata": {},
   "source": [
    "### Fill nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17471469-e6a9-4d05-9c89-97f7ed07a4c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(var, dir_out):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the specified variable's dataset using the nearest valid \n",
    "    data, applies a land mask, and exports the result to a new Zarr dataset.\n",
    "\n",
    "    Args:\n",
    "        var (str): Name of the variable to process (e.g., 'temperature', 'precipitation').\n",
    "        dir_out (str): Directory where prepared data is stored and the filled dataset will be exported.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def fill_nans_array(data, invalid):\n",
    "        \"\"\"\n",
    "        Replace invalid (NaN) data cells by the value of the nearest valid data \n",
    "        cell.\n",
    "        \"\"\"\n",
    "        ind = ndimage.distance_transform_edt(invalid,\n",
    "                                             return_distances=False,\n",
    "                                             return_indices=True)\n",
    "        return data[tuple(ind)]\n",
    "\n",
    "    # Paths for input and output\n",
    "    land_mask_path = os.path.join(dir_out, 'ds_prep_copernicus_land_mask.zarr')\n",
    "    var_data_path = os.path.join(dir_out, f'ds_regridded_{var}.zarr')\n",
    "    output_path = os.path.join(dir_out, f'ds_prep_{var}.zarr')\n",
    "\n",
    "    # Read land mask data\n",
    "    da_land = xr.open_zarr(land_mask_path) \\\n",
    "                .chunk(dict(lat=5000, lon=5000)) \\\n",
    "                .copernicus_land_mask \\\n",
    "                .compute()\n",
    "\n",
    "    # Read variable data\n",
    "    da_var = xr.open_zarr(var_data_path)['regridded_' + var]\n",
    "\n",
    "    # Fill nan using function fill_nans_array\n",
    "    # If there are no NaNs, skip filling process\n",
    "    if not da_var.isnull().any():\n",
    "        da_fill = da_var.values  # No filling required\n",
    "    else:\n",
    "        da_fill = fill_nans_array(da_var.values, da_var.isnull().values)\n",
    "\n",
    "    # Create a new Dataset with filled data\n",
    "    ds_filled = xr.Dataset(dict(lat = da_var.lat, lon=da_var.lon))\n",
    "    ds_filled[var] = (('lat', 'lon'), da_fill)\n",
    "\n",
    "    # Apply land mask to the filled data\n",
    "    ds_filled = ds_filled.where(da_land)\n",
    "\n",
    "    # Export the filled dataset to Zarr format\n",
    "    ds_filled.chunk(dict(lat=5000, lon=5000)) \\\n",
    "             .to_zarr(output_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a4bda9-33d5-424d-ad63-cf03af9fbe79",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in ['spawn_agbc', 'spawn_bgbc', 'spawn_agbcunc', 'spawn_bgbcunc']:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb67ba3-5f2e-44d6-9055-bb5551ad8285",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6cbe013-3fb6-424f-985c-cf716683897b",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cb77cd-696c-45ca-a809-fb3097a3895b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "for i in ['spawn_agbc', 'spawn_bgbc', 'spawn_agbcunc', 'spawn_bgbcunc']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
