{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "89847275-629e-4356-89d6-e7979651e369",
   "metadata": {},
   "source": [
    "# Prepare HILDA+ LUC data (Winkler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce08601f-0a55-4cd0-9cdb-61708b6d61b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, time, shutil, rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b344ceff-1949-424f-a547-93a5e15100b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data =  '../data/'\n",
    "dir01 = '../paper_deficit/output/01_prep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bbdf89-a9c5-4acd-9065-a3ad8e0cec2f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cb9b84-374e-4ee5-8a4a-3007c7319c5a",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b62de30c-4876-4c9f-8f29-f1a2d0862240",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=24,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='00:30:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=10)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c210265c-2641-41ee-a077-27edb96ab4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to trim memory of workers\n",
    "def trim_memory() -> int:\n",
    "    import ctypes\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05e1c5da-2cf2-4de5-93b9-f60fc593fe92",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_hilda_stable():\n",
    "    \"\"\"\n",
    "    Prepare HILDA data. This process includes reading the HILDA dataset, \n",
    "    extracting land cover classes, identifying stable grid cells, and exporting \n",
    "    the results.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the HILDA dataset, selecting data from 1960 onwards\n",
    "    hilda = xr.open_dataset(\n",
    "        f'{dir_data}hilda/hildap_vGLOB-1.0-f_netcdf/hildaplus_GLOB-1-0-f_states.nc',\n",
    "        decode_coords='all') \\\n",
    "        .chunk({'latitude': 5000, 'longitude': 5000, 'time': 1}) \\\n",
    "        .sel(time=slice(1960, 2020)) \\\n",
    "        .LULC_states\n",
    "\n",
    "    # Create a new dataset with each land cover class as a separate variable\n",
    "    hilda_processed = xr.Dataset({\n",
    "        'lat': hilda.latitude.values,\n",
    "        'lon': hilda.longitude.values,\n",
    "        'time': hilda.time.astype('int')\n",
    "    })\n",
    "\n",
    "    land_cover_classes = [22, 33, 40, 41, 42, 43, 44, 45, 55, 66]\n",
    "    for lc_class in land_cover_classes:\n",
    "        hilda_processed[f'hilda_{lc_class}'] = (\n",
    "            ('time', 'lat', 'lon'),\n",
    "            xr.where(hilda == lc_class, True, False).data)\n",
    "\n",
    "    # Export the processed dataset to Zarr format\n",
    "    hilda_processed.to_zarr(f'{dir01}hilda_prep.zarr', mode='w')\n",
    "\n",
    "    # Open the newly saved dataset and re-chunk for efficiency\n",
    "    hilda_prep = xr.open_zarr(f'{dir01}hilda_prep.zarr') \\\n",
    "        .chunk({'lat': 5000, 'lon': 5000, 'time': -1})\n",
    "\n",
    "    # Identify grid cells without land cover change across the entire time period (60 years)\n",
    "    stable_cells = xr.where(hilda_prep.sum('time') == 60, True, False)\n",
    "\n",
    "    # Store stable land cover information in a new dataset\n",
    "    hilda_stable = xr.Dataset()\n",
    "    hilda_stable['hilda_stable_crop'] = stable_cells.hilda_22\n",
    "    hilda_stable['hilda_stable_pasture'] = stable_cells.hilda_33\n",
    "    hilda_stable['hilda_stable_fso'] = (\n",
    "        stable_cells.hilda_40 + stable_cells.hilda_41 +\n",
    "        stable_cells.hilda_42 + stable_cells.hilda_43 +\n",
    "        stable_cells.hilda_44 + stable_cells.hilda_45 +\n",
    "        stable_cells.hilda_55 + stable_cells.hilda_66\n",
    "    )\n",
    "\n",
    "    # Export the stable land cover dataset to Zarr format\n",
    "    hilda_stable \\\n",
    "        .chunk({'lat': 5000, 'lon': 5000}) \\\n",
    "        .to_zarr(f'{dir01}hilda_stable.zarr', mode='w')\n",
    "\n",
    "    # Convert the Zarr dataset to GeoTIFF format for each variable\n",
    "    for variable in hilda_stable.data_vars:\n",
    "        xr.open_zarr(f'{dir01}hilda_stable.zarr')[variable] \\\n",
    "            .rename({'lat': 'y', 'lon': 'x'}) \\\n",
    "            .astype('float32') \\\n",
    "            .rio.to_raster(f'{dir01}{variable}.tif')\n",
    "\n",
    "        # Trim memory after each export\n",
    "        client.run(trim_memory)\n",
    "\n",
    "    # Clean up intermediate files to free up disk space\n",
    "    shutil.rmtree(f'{dir01}hilda_prep.zarr')\n",
    "    shutil.rmtree(f'{dir01}hilda_stable.zarr')\n",
    "    client.run(trim_memory)\n",
    "\n",
    "\n",
    "%time prep_hilda_stable()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e6723d-5f0c-4eb6-be33-12b53650d0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_hilda2015():\n",
    "    \"\"\"Reclassify hilda data of year 2015 to 6 LUC groups\"\"\"\n",
    "\n",
    "    # File path\n",
    "    file_path = f'{dir_data}hilda/hildap_vGLOB-1.0-f_netcdf/hildaplus_GLOB-1-0-f_states.nc'\n",
    "\n",
    "    # Get data\n",
    "    ds_hilda = xr.open_dataset(file_path, decode_coords='all') \\\n",
    "        .chunk(dict(latitude=5000, longitude=5000, time=1))\n",
    "    \n",
    "    # Select year\n",
    "    da_hilda = ds_hilda.LULC_states.sel(time=2015).drop_vars('time') \n",
    "\n",
    "    # Create dataset with one variable for each luc class\n",
    "    ds_hilda_out = xr.Dataset()\n",
    "    ds_hilda_out['urban'] = xr.where(da_hilda == 11, 1, 0)\n",
    "    ds_hilda_out['crop'] = xr.where(da_hilda == 22, 1, 0)\n",
    "    ds_hilda_out['pasture'] = xr.where(da_hilda == 33, 1, 0)\n",
    "    ds_hilda_out['forest'] = xr.where(\n",
    "        da_hilda.isin([40, 41, 42, 43, 44, 45]), 1, 0)\n",
    "    ds_hilda_out['shrub'] = xr.where(da_hilda == 55, 1, 0)\n",
    "    ds_hilda_out['other'] = xr.where(da_hilda == 66, 1, 0)\n",
    "    \n",
    "    # Set non-land value to zero, rename lat and lon\n",
    "    ds_hilda_out = ds_hilda_out \\\n",
    "        .where(da_hilda != 0) \\\n",
    "        .rename(dict(latitude='y', longitude='x'))\n",
    "    \n",
    "    # export as tif\n",
    "    for i in ds_hilda_out.data_vars:\n",
    "        ds_hilda_out[i].rio.to_raster(dir01 + 'hilda2015_' + i + '.tif')\n",
    "\n",
    "\n",
    "%time prep_hilda2015()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d8fe201-6794-482d-86e1-68e66beb8161",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dask cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca3df7-7fbb-46e0-bf72-bbf3c4719093",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for 60s for dask client to completely disconnect\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bab7226-67bb-46ae-b605-caed73062a0c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27d11a0-261a-43e7-9351-4c81fe6c164b",
   "metadata": {},
   "source": [
    "### Regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "920e54b3-c585-4129-915d-4ce5fd7ee378",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regridding function\n",
    "from regrid_high_res_v1_01 import regrid_high_res, prep_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db4537-8a16-4933-abee-1259e2655ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_da(f_source, dir_target, dir_source, dir_out, \n",
    "              size_tiles, fill_value=None, olap=1):  \n",
    "    \"\"\"Regrid large xarray dataarrays.\n",
    "\n",
    "    Args:\n",
    "        f_source (str): The filename (without extension) of the source .tif file to be regridded.\n",
    "        dir_target (str): Directory containing target grid .tif file.\n",
    "        dir_source (str): Directory containing the the source  .tif file.\n",
    "        dir_out (str): Directory to store the output and intermediate files.\n",
    "        size_tiles (int): Size of the regridding tiles in degrees.\n",
    "        fill_value (float, optional): Fill value to use in the regridding process. Defaults to None.\n",
    "        olap (int, optional): Overlap size in degrees for regridding tiles. Defaults to 1.\n",
    "        \n",
    "    Returns:\n",
    "        xarray.Dataset: The combined dataset after regridding.\n",
    "    \"\"\"\n",
    "    # Prepare the target and source data arrays from TIFF files\n",
    "    da_target = prep_tif(dir_target + 'target_grid.tif', 'target_grid')\n",
    "    da_source = prep_tif(dir_source + f_source + '.tif', f_source)\n",
    "    # Regridd source array to target grid\n",
    "    regrid_high_res(da_target, da_source, dir_out,\n",
    "                    account='bm0891', partition='shared',\n",
    "                    size_tiles=size_tiles, olap=olap, fill_value = fill_value,\n",
    "                    type_export='zarr', del_interm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02ae1c3f-c77c-4487-844b-09f14d28761b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regridding\n",
    "for i in ['hilda_stable_crop', 'hilda_stable_pasture', 'hilda_stable_fso']:\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 30, np.nan, 0.1)\n",
    "# Takes about 4min for one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df25d2ae-eb1b-4722-b37b-28108065eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['hilda2015_urban', 'hilda2015_crop', 'hilda2015_pasture', \n",
    "         'hilda2015_forest', 'hilda2015_shrub', 'hilda2015_other']:\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 30, np.nan, 0.1)\n",
    "# Takes about 4min for one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b112a346-f627-433d-af9e-6a6f7e2c97a5",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b201f75d-b9c9-4e2b-8df2-c257f16b2bde",
   "metadata": {},
   "source": [
    "### Fill nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78ca684f-b3db-4515-9070-eb7d367b3c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(var, dir_out):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the specified variable's dataset using the nearest valid \n",
    "    data, applies a land mask, and exports the result to a new Zarr dataset.\n",
    "\n",
    "    Args:\n",
    "        var (str): Name of the variable to process (e.g., 'temperature', 'precipitation').\n",
    "        dir_out (str): Directory where prepared data is stored and the filled dataset will be exported.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def fill_nans_array(data, invalid):\n",
    "        \"\"\"\n",
    "        Replace invalid (NaN) data cells by the value of the nearest valid data \n",
    "        cell.\n",
    "        \"\"\"\n",
    "        ind = ndimage.distance_transform_edt(invalid,\n",
    "                                             return_distances=False,\n",
    "                                             return_indices=True)\n",
    "        return data[tuple(ind)]\n",
    "\n",
    "    # Paths for input and output\n",
    "    land_mask_path = os.path.join(dir_out, 'ds_prep_copernicus_land_mask.zarr')\n",
    "    var_data_path = os.path.join(dir_out, f'ds_regridded_{var}.zarr')\n",
    "    output_path = os.path.join(dir_out, f'ds_prep_{var}.zarr')\n",
    "\n",
    "    # Read land mask data\n",
    "    da_land = xr.open_zarr(land_mask_path) \\\n",
    "                .chunk(dict(lat=5000, lon=5000)) \\\n",
    "                .copernicus_land_mask \\\n",
    "                .compute()\n",
    "\n",
    "    # Read variable data\n",
    "    da_var = xr.open_zarr(var_data_path)['regridded_' + var]\n",
    "\n",
    "    # Fill nan using function fill_nans_array\n",
    "    # If there are no NaNs, skip filling process\n",
    "    if not da_var.isnull().any():\n",
    "        da_fill = da_var.values  # No filling required\n",
    "    else:\n",
    "        da_fill = fill_nans_array(da_var.values, da_var.isnull().values)\n",
    "\n",
    "    # Create a new Dataset with filled data\n",
    "    ds_filled = xr.Dataset(dict(lat = da_var.lat, lon=da_var.lon))\n",
    "    ds_filled[var] = (('lat', 'lon'), da_fill)\n",
    "\n",
    "    # Apply land mask to the filled data\n",
    "    ds_filled = ds_filled.where(da_land)\n",
    "\n",
    "    # Export the filled dataset to Zarr format\n",
    "    ds_filled.chunk(dict(lat=5000, lon=5000)) \\\n",
    "             .to_zarr(output_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5651299-c4f4-43d1-b92e-408b028eec31",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in ['hilda_stable_crop', 'hilda_stable_pasture', 'hilda_stable_fso']:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b279ff83-dc3d-4740-8625-fd376d15df53",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['hilda2015_urban', 'hilda2015_crop', 'hilda2015_pasture', \n",
    "         'hilda2015_forest', 'hilda2015_shrub', 'hilda2015_other']:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c431cd41-dfce-4b31-912f-1a0f03d2e467",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68d82566-6bee-46f7-9e33-51f7959d1d66",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f66762-122b-4d24-a19a-d755f98646c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "for i in ['hilda_stable_crop', 'hilda_stable_pasture', 'hilda_stable_fso']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d81c89dd-8e39-4573-9b5f-aba6748e6f32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "for i in ['hilda2015_urban', 'hilda2015_crop', 'hilda2015_pasture', \n",
    "          'hilda2015_forest', 'hilda2015_shrub', 'hilda2015_other']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
