{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "620d1b07-90bc-4ea6-9188-fbf95d3d7fdf",
   "metadata": {},
   "source": [
    "# Prepare ESA CCI biomass data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a53c96-c715-41af-abc9-7831720fa54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, time, shutil, rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from dask.distributed import Lock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560c0f9a-6feb-4e72-894b-4876bfa86edd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data =  '../data/'\n",
    "dir01 = '../paper_deficit/output/01_prep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1abc2508-98e3-4d89-9236-608af215194d",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f70d787c-a861-4249-9923-cafb0783bad9",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e504508-f3e0-4632-8460-c6c5e5567c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=24,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='01:00:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=10)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e6d4789-52a9-4c9b-abcb-1342581a84a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to trim memory of workers\n",
    "def trim_memory() -> int:\n",
    "    import ctypes\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3347ce96-b2d9-4185-9578-554b0711f880",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_esabio():\n",
    "\n",
    "    \"\"\"\n",
    "    Prepare ESA CCI biomass data for regridding\n",
    "    \"\"\"\n",
    "    \n",
    "    for var in ['agb', 'agbsd']:\n",
    "        for year in [2015, 2016, 2017, 2018, 2019, 2020, 2021]:\n",
    "            # File path\n",
    "            file_path = dir_data + 'esa_biomass/v5_01/' + \\\n",
    "                'ESACCI-BIOMASS-L4-AGB-MERGED-1000m-fv5.01.nc'\n",
    "            # Get data\n",
    "            ds = xr.open_dataset(file_path).chunk(dict(lat=5000, lon=5000))\n",
    "            # Select array\n",
    "            if var == 'agb':\n",
    "                da = ds['agb'].rename('esabio_agb' + str(year))\n",
    "            if var == 'agbsd':\n",
    "                da = ds['agb_sd'].rename('esabio_agbsd' + str(year))\n",
    "            # Select year and rename\n",
    "            da = da.sel(time=str(year)).squeeze('time').drop_vars('time').astype(np.float32)\n",
    "            # Remove attributes (creates problems with CDO)\n",
    "            da.attrs = {}\n",
    "            # Export as tif\n",
    "            da.rio.to_raster(dir01 + 'esabio_' + var + str(year) + '.tif')\n",
    "\n",
    "\n",
    "%time prep_esabio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73aed746-b209-48fa-b32f-d1141cc02953",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dask cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26e0d9e2-8c37-4279-bd55-531d63e7ffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for 60s for dask client to completely disconnect\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cad33a5-b94f-4f27-ac30-ffcc4e90e5cb",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73241d05-6b47-4779-abbe-9ed5c1a0223a",
   "metadata": {},
   "source": [
    "### Regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b91ff8c3-7349-428d-ad3b-5abd4e586346",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regridding function\n",
    "from regrid_high_res_v1_01 import regrid_high_res, prep_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7d841f6-7a02-49bc-9c1f-fce4111a86ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_da(f_source, dir_target, dir_source, dir_out, \n",
    "              size_tiles, fill_value=None, olap=1):  \n",
    "    \"\"\"Regrid large xarray dataarrays.\n",
    "\n",
    "    Args:\n",
    "        f_source (str): The filename (without extension) of the source .tif file to be regridded.\n",
    "        dir_target (str): Directory containing target grid .tif file.\n",
    "        dir_source (str): Directory containing the the source  .tif file.\n",
    "        dir_out (str): Directory to store the output and intermediate files.\n",
    "        size_tiles (int): Size of the regridding tiles in degrees.\n",
    "        fill_value (float, optional): Fill value to use in the regridding process. Defaults to None.\n",
    "        olap (int, optional): Overlap size in degrees for regridding tiles. Defaults to 1.\n",
    "        \n",
    "    Returns:\n",
    "        xarray.Dataset: The combined dataset after regridding.\n",
    "    \"\"\"\n",
    "    # Prepare the target and source data arrays from TIFF files\n",
    "    da_target = prep_tif(dir_target + 'target_grid.tif', 'target_grid')\n",
    "    da_source = prep_tif(dir_source + f_source + '.tif', f_source)\n",
    "    # Regridd source array to target grid\n",
    "    regrid_high_res(da_target, da_source, dir_out,\n",
    "                    account='bm0891', partition='compute',\n",
    "                    size_tiles=size_tiles, olap=olap, fill_value = fill_value,\n",
    "                    type_export='zarr', del_interm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7d5668-7b20-4412-94b1-89d347d57220",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [2015, 2016, 2017, 2018, 2019, 2020, 2021]:\n",
    "    %time regrid_da('esabio_agb' + str(i), dir01, dir01, dir01, \\\n",
    "                    30, np.nan, 0.1)\n",
    "# Takes about 6 min for one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f9b9ecb-40cd-4203-8118-5f5e287ea611",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in [2015, 2016, 2017, 2018, 2019, 2020, 2021]:\n",
    "    %time regrid_da('esabio_agbsd' + str(i), dir01, dir01, dir01, \\\n",
    "                    30, np.nan, 0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40f009ee-2877-498a-9bc6-e96fceee545a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b8f1c1a-8b42-416b-91fb-ff6433b896a9",
   "metadata": {},
   "source": [
    "### Fill nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c4fc23-7f87-400b-b3b5-5169f13a1b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(var, dir_out):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the specified variable's dataset using the nearest valid \n",
    "    data, applies a land mask, and exports the result to a new Zarr dataset.\n",
    "\n",
    "    Args:\n",
    "        var (str): Name of the variable to process (e.g., 'temperature', 'precipitation').\n",
    "        dir_out (str): Directory where prepared data is stored and the filled dataset will be exported.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def fill_nans_array(data, invalid):\n",
    "        \"\"\"\n",
    "        Replace invalid (NaN) data cells by the value of the nearest valid data \n",
    "        cell.\n",
    "        \"\"\"\n",
    "        ind = ndimage.distance_transform_edt(invalid,\n",
    "                                             return_distances=False,\n",
    "                                             return_indices=True)\n",
    "        return data[tuple(ind)]\n",
    "\n",
    "    # Paths for input and output\n",
    "    land_mask_path = os.path.join(dir_out, 'ds_prep_copernicus_land_mask.zarr')\n",
    "    var_data_path = os.path.join(dir_out, f'ds_regridded_{var}.zarr')\n",
    "    output_path = os.path.join(dir_out, f'ds_prep_{var}.zarr')\n",
    "\n",
    "    # Read land mask data\n",
    "    da_land = xr.open_zarr(land_mask_path) \\\n",
    "                .chunk(dict(lat=5000, lon=5000)) \\\n",
    "                .copernicus_land_mask \\\n",
    "                .compute()\n",
    "\n",
    "    # Read variable data\n",
    "    da_var = xr.open_zarr(var_data_path)['regridded_' + var]\n",
    "\n",
    "    # Fill nan using function fill_nans_array\n",
    "    # If there are no NaNs, skip filling process\n",
    "    if not da_var.isnull().any():\n",
    "        da_fill = da_var.values  # No filling required\n",
    "    else:\n",
    "        da_fill = fill_nans_array(da_var.values, da_var.isnull().values)\n",
    "\n",
    "    # Create a new Dataset with filled data\n",
    "    ds_filled = xr.Dataset(dict(lat = da_var.lat, lon=da_var.lon))\n",
    "    ds_filled[var] = (('lat', 'lon'), da_fill)\n",
    "\n",
    "    # Apply land mask to the filled data\n",
    "    ds_filled = ds_filled.where(da_land)\n",
    "\n",
    "    # Export the filled dataset to Zarr format\n",
    "    ds_filled.chunk(dict(lat=5000, lon=5000)) \\\n",
    "             .to_zarr(output_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24b012e-b2b2-4135-baa2-29ff23dd2f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['esabio_agb2015', 'esabio_agb2016', 'esabio_agb2017',\n",
    "          'esabio_agb2018', 'esabio_agb2019', 'esabio_agb2020',\n",
    "          'esabio_agb2021']:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c25a9f-c958-4cb3-9ceb-7beace1c6128",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['esabio_agbsd2015', 'esabio_agbsd2016', 'esabio_agbsd2017',\n",
    "          'esabio_agbsd2018', 'esabio_agbsd2019', 'esabio_agbsd2020',\n",
    "          'esabio_agbsd2021']:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78d9f6-a1d0-466d-abcb-e49a1f042175",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8707d7e-b2f3-4c02-ac03-f527fbe558f1",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da59a83d-940c-4a94-ad0e-4db04ce3a5be",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "for i in ['esabio_agb2015', 'esabio_agb2016', 'esabio_agb2017', \n",
    "          'esabio_agb2018', 'esabio_agb2019', 'esabio_agb2020',\n",
    "          'esabio_agb2021']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax, robust=True)\n",
    "    ax.set_title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f667031-631d-4474-91ed-55192b889317",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "for i in ['esabio_agbsd2015', 'esabio_agbsd2016', 'esabio_agbsd2017', \n",
    "          'esabio_agbsd2018', 'esabio_agbsd2019', 'esabio_agbsd2020',\n",
    "          'esabio_agbsd2021']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax, robust=True)\n",
    "    ax.set_title(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
