{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2290eddd-1fb1-41ad-b49c-f19cbd510633",
   "metadata": {},
   "source": [
    "# Prepare soilgrids data (Poggio, Hengl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aadb4259-9714-4b4d-8082-e035647725ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, time, shutil, rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "542676fa-7ac5-448e-b37a-905fa2a22f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data =  '../data/'\n",
    "dir01 = '../paper_deficit/output/01_prep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4990f2ca-3685-413c-ae4c-30bebfda26a8",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "505f7e79-d364-46fe-9b74-bd6478e7cd6d",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8394c9c-b1fb-4ffa-9b41-e76155988747",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=24,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='01:00:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=10)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1b8899e-a072-4194-8481-e0b50d2f466f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to trim memory of workers\n",
    "def trim_memory() -> int:\n",
    "    import ctypes\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1ca3797-8fbc-427e-a886-a7d6b65026b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_soilgrids2020():\n",
    "    \"\"\"Load and prepare soilgrids 2020 data for regridding\"\"\"\n",
    "    \n",
    "    def _func_soilgrids2020_load(var, depth):\n",
    "        \"\"\"Load soilgrids data\"\"\"\n",
    "        # File\n",
    "        file_path = (dir_data + 'soilgrids/soilgrids2020/' + var + '/' + var + \n",
    "                    '_' + depth + '_mean.tif')\n",
    "        # Load file\n",
    "        da = rioxarray.open_rasterio(file_path, \n",
    "                                     chunks=dict(y=10000, x=10000))\n",
    "        # Set non-land to nan and return\n",
    "        return da.where(da != da.attrs.get('_FillValue'))\n",
    "        \n",
    "    # Prepare soilgrids 2020 data\n",
    "    for var in ['bdod', 'cec', 'cfvo', 'clay', 'nitrogen', 'ocd', 'phh2o',\n",
    "                'sand', 'silt', 'soc']:\n",
    "        # Read data\n",
    "        a = _func_soilgrids2020_load(var, '0-5cm')\n",
    "        b = _func_soilgrids2020_load(var, '5-15cm')\n",
    "        c = _func_soilgrids2020_load(var, '15-30cm')\n",
    "        \n",
    "        # Averarge over the layers and round\n",
    "        da = ((a*5 + b*10 + c*15) / 30) \\\n",
    "                    .round(0) \\\n",
    "                    .astype('int16')\n",
    "        # Set nan value to default value\n",
    "        da_out = xr.where(a.isnull(), a.attrs.get('_FillValue'), da)\n",
    "        # Add attributes\n",
    "        da_out.spatial_ref.attrs = a.spatial_ref.attrs\n",
    "        for attr in ['_FillValue', 'scale_factor', 'add_offset']:\n",
    "            da_out.attrs[attr] = a.attrs.get(attr)\n",
    "        # Export\n",
    "        da_out.rio.to_raster(dir01 + 'soilgrids2020_' + var + '.tif')\n",
    "        # Release memory\n",
    "        client.run(trim_memory);\n",
    "\n",
    "\n",
    "%time prep_soilgrids2020()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0fcfc4-0829-4de4-962a-57abd3153a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_soilgrids2020_ocs():\n",
    "    \"\"\"Load and prepare soilgrids 2020 organic carbon stocks data for\n",
    "    regridding\"\"\"\n",
    "\n",
    "    # in soilgrids: \n",
    "    # ocs = organic carbon stocks (t/ha); \n",
    "    # soc = Soil organic carbon content in the fine earth fraction (dg/kg)\n",
    "    dir_data_ocs = dir_data + 'soilgrids/soilgrids2020/ocs/'\n",
    "    file_path_ocs = dir_data_ocs + 'ocs_0-30cm_mean.tif'\n",
    "    file_path_ocsunc = dir_data_ocs + 'ocs_0-30cm_uncertainty.tif'\n",
    "    \n",
    "    # Prepare ocs data for regridding\n",
    "    rioxarray.open_rasterio(file_path_ocs, chunks = dict(y=10000, x=10000)) \\\n",
    "        .rename('sgrids_ocs_2020_30cm') \\\n",
    "        .drop_vars('spatial_ref') \\\n",
    "        .rio.to_raster(dir01 + 'soilgrids2020_ocs_0-30cm.tif')\n",
    "\n",
    "    # Prepare ocs uncertainty data for regridding\n",
    "    rioxarray.open_rasterio(file_path_ocsunc, chunks = dict(y=10000, x=10000)) \\\n",
    "        .rename('sgrids_ocsunc_2020_30cm') \\\n",
    "        .drop_vars('spatial_ref') \\\n",
    "        .rio.to_raster(dir01 + 'soilgrids2020_ocsunc_0-30cm.tif')\n",
    "\n",
    "\n",
    "%time prep_soilgrids2020_ocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ab3e0-604a-4fee-a2c3-3154be588382",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_soilgrids2017_ocs():\n",
    "    \"\"\"Load and prepare soilgrids 2017 organic carbon stocks data for\n",
    "    regridding\"\"\"\n",
    "    \n",
    "    def _get_soilgrids2017_ocs_da(sdx):\n",
    "        # Load data\n",
    "        da = rioxarray.open_rasterio(\n",
    "            dir_data + 'soilgrids/soilgrids2017/OCSTHA_M_' + sdx + '_250m_ll.tif', \n",
    "            chunks=dict(y=10000, x=10000))[0]\n",
    "        # Change FillValue to nan\n",
    "        da = da.where(da != da.attrs.get('_FillValue'))\n",
    "        return da\n",
    "    \n",
    "    def _prep_soilgrids2017_ocs_da(da):\n",
    "        # Replace nan values and change dtype to integer\n",
    "        da = da.fillna(-32768).round(0).astype('int16')\n",
    "        da.attrs = dict(_FillValue = -32768,\n",
    "                    scale_factor = 1.0,\n",
    "                    add_offset = 0.0)\n",
    "        return da\n",
    "\n",
    "    # Load data\n",
    "    da_sd1 = _get_soilgrids2017_ocs_da('sd1')\n",
    "    da_sd2 = _get_soilgrids2017_ocs_da('sd2')\n",
    "    da_sd3 = _get_soilgrids2017_ocs_da('sd3')\n",
    "    da_sd4 = _get_soilgrids2017_ocs_da('sd4')\n",
    "    da_sd5 = _get_soilgrids2017_ocs_da('sd5')\n",
    "    da_sd6 = _get_soilgrids2017_ocs_da('sd6')\n",
    "\n",
    "    # Prepare and export\n",
    "    _prep_soilgrids2017_ocs_da(da_sd1 + da_sd2 + da_sd3) \\\n",
    "        .rename('soilgrids2017_ocs_0-30cm') \\\n",
    "        .rio.to_raster(dir01 + 'soilgrids2017_ocs_0-30cm.tif')\n",
    "    _prep_soilgrids2017_ocs_da(da_sd4 + da_sd5) \\\n",
    "        .rename('soilgrids2017_ocs_30-100cm') \\\n",
    "        .rio.to_raster(dir01 + 'soilgrids2017_ocs_30-100cm.tif')\n",
    "    _prep_soilgrids2017_ocs_da(da_sd6) \\\n",
    "        .rename('soilgrids2017_ocs_100-200cm') \\\n",
    "        .rio.to_raster(dir01 + 'soilgrids2017_ocs_100-200cm.tif')\n",
    "\n",
    "\n",
    "%time prep_soilgrids2017_ocs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cfa049-48d9-4be3-ae81-e446e1429de6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_soilgrids2017_other():\n",
    "    \"\"\"Load and prepare soilgrids 2017 bdricm, bdrlog, bdticm data for\n",
    "    regridding\"\"\"\n",
    "    \n",
    "    for i in ['bdricm', 'bdrlog', 'bdticm']:\n",
    "        file_path = dir_data + 'soilgrids/soilgrids2017/' + i.upper() + \\\n",
    "            '_M_250m_ll.tif'\n",
    "        \n",
    "        rioxarray.open_rasterio(file_path, chunks = dict(y=10000, x=10000)) \\\n",
    "            .rename('sgrids_' + i) \\\n",
    "            .drop_vars('spatial_ref') \\\n",
    "            .rio.to_raster(dir01 + 'soilgrids2017_' + i + '.tif')\n",
    "\n",
    "\n",
    "%time prep_soilgrids2017_other()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ed0adc-5f06-4bd7-8aef-849357216933",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dask cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749069d4-85a3-4201-94f1-3cb1b6fe6ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for 60s for dask client to completely disconnect\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b26519a-afbf-4698-bcc7-7bbcaa8f622a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09ef3ea-1e0d-4088-8543-696801d4c00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regridding function\n",
    "from regrid_high_res_v1_01 import regrid_high_res, prep_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4a1924-aafd-4138-b858-47f1c199c0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_da(f_source, dir_target, dir_source, dir_out, \n",
    "              size_tiles, fill_value=None, olap=1):  \n",
    "    \"\"\"Regrid large xarray dataarrays.\n",
    "\n",
    "    Args:\n",
    "        f_source (str): The filename (without extension) of the source .tif file to be regridded.\n",
    "        dir_target (str): Directory containing target grid .tif file.\n",
    "        dir_source (str): Directory containing the the source  .tif file.\n",
    "        dir_out (str): Directory to store the output and intermediate files.\n",
    "        size_tiles (int): Size of the regridding tiles in degrees.\n",
    "        fill_value (float, optional): Fill value to use in the regridding process. Defaults to None.\n",
    "        olap (int, optional): Overlap size in degrees for regridding tiles. Defaults to 1.\n",
    "        \n",
    "    Returns:\n",
    "        xarray.Dataset: The combined dataset after regridding.\n",
    "    \"\"\"\n",
    "    # Prepare the target and source data arrays from TIFF files\n",
    "    da_target = prep_tif(dir_target + 'target_grid.tif', 'target_grid')\n",
    "    da_source = prep_tif(dir_source + f_source + '.tif', f_source)\n",
    "    # Regridd source array to target grid\n",
    "    regrid_high_res(da_target, da_source, dir_out,\n",
    "                    account='bm0891', partition='compute',\n",
    "                    size_tiles=size_tiles, olap=olap, fill_value = fill_value,\n",
    "                    type_export='zarr', del_interm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dda2bc9-aff9-454c-bd3b-56d2e1ab7b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regridding soilgrids 2020\n",
    "for i in ['soilgrids2020_cec', 'soilgrids2020_phh2o', 'soilgrids2020_sand',\n",
    "          'soilgrids2020_soc', 'soilgrids2020_clay', 'soilgrids2020_ocs_0-30cm',\n",
    "          'soilgrids2020_nitrogen', 'soilgrids2020_cfvo', 'soilgrids2020_ocd',\n",
    "          'soilgrids2020_bdod', 'soilgrids2020_silt']:\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 20, -32768, 0.1)\n",
    "\n",
    "%time regrid_da('soilgrids2020_ocsunc_0-30cm', dir01, dir01, dir01, \\\n",
    "                20, 65535, 0.1)\n",
    "# Takes about 9-13 min for one file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe2f645-e6c1-4d24-8394-a74490242686",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Regridding soilgrids 2017\n",
    "for i in ['soilgrids2017_ocs_0-30cm', 'soilgrids2017_ocs_30-100cm',\n",
    "          'soilgrids2017_ocs_100-200cm', 'soilgrids2017_bdticm']:\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 20, -32768, 0.1)\n",
    "\n",
    "for i in ['soilgrids2017_bdricm', 'soilgrids2017_bdrlog']:\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 20, 255, 0.1)\n",
    "# Takes about 9-13 min for one file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cb995a7-74e3-46d0-8765-d601d027933c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d396a71e-3749-48ca-a0c8-658002bca83d",
   "metadata": {},
   "source": [
    "### Fill nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb03b2c-72a4-49fa-b0c5-75bbe2af7aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(var, dir_out):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the specified variable's dataset using the nearest valid \n",
    "    data, applies a land mask, and exports the result to a new Zarr dataset.\n",
    "\n",
    "    Args:\n",
    "        var (str): Name of the variable to process (e.g., 'temperature', 'precipitation').\n",
    "        dir_out (str): Directory where prepared data is stored and the filled dataset will be exported.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def fill_nans_array(data, invalid):\n",
    "        \"\"\"\n",
    "        Replace invalid (NaN) data cells by the value of the nearest valid data \n",
    "        cell.\n",
    "        \"\"\"\n",
    "        ind = ndimage.distance_transform_edt(invalid,\n",
    "                                             return_distances=False,\n",
    "                                             return_indices=True)\n",
    "        return data[tuple(ind)]\n",
    "\n",
    "    # Paths for input and output\n",
    "    land_mask_path = os.path.join(dir_out, 'ds_prep_copernicus_land_mask.zarr')\n",
    "    var_data_path = os.path.join(dir_out, f'ds_regridded_{var}.zarr')\n",
    "    output_path = os.path.join(dir_out, f'ds_prep_{var}.zarr')\n",
    "\n",
    "    # Read land mask data\n",
    "    da_land = xr.open_zarr(land_mask_path) \\\n",
    "                .chunk(dict(lat=5000, lon=5000)) \\\n",
    "                .copernicus_land_mask \\\n",
    "                .compute()\n",
    "\n",
    "    # Read variable data\n",
    "    da_var = xr.open_zarr(var_data_path)['regridded_' + var]\n",
    "\n",
    "    # Fill nan using function fill_nans_array\n",
    "    # If there are no NaNs, skip filling process\n",
    "    if not da_var.isnull().any():\n",
    "        da_fill = da_var.values  # No filling required\n",
    "    else:\n",
    "        da_fill = fill_nans_array(da_var.values, da_var.isnull().values)\n",
    "\n",
    "    # Create a new Dataset with filled data\n",
    "    ds_filled = xr.Dataset(dict(lat = da_var.lat, lon=da_var.lon))\n",
    "    ds_filled[var] = (('lat', 'lon'), da_fill)\n",
    "\n",
    "    # Apply land mask to the filled data\n",
    "    ds_filled = ds_filled.where(da_land)\n",
    "\n",
    "    # Export the filled dataset to Zarr format\n",
    "    ds_filled.chunk(dict(lat=5000, lon=5000)) \\\n",
    "             .to_zarr(output_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7719d291-9cd2-437f-9485-e81b92a58f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in ['soilgrids2020_cec', 'soilgrids2020_phh2o', 'soilgrids2020_sand',\n",
    "          'soilgrids2020_soc', 'soilgrids2020_clay', 'soilgrids2020_ocs_0-30cm',\n",
    "          'soilgrids2020_nitrogen', 'soilgrids2020_cfvo', 'soilgrids2020_ocd',\n",
    "          'soilgrids2020_bdod', 'soilgrids2020_silt', \n",
    "          'soilgrids2020_ocsunc_0-30cm']:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f0b161-b96a-4379-bea1-2f3adcc4ab99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in ['soilgrids2017_ocs_0-30cm', 'soilgrids2017_ocs_30-100cm',\n",
    "          'soilgrids2017_ocs_100-200cm', 'soilgrids2017_bdticm',\n",
    "          'soilgrids2017_bdricm', 'soilgrids2017_bdrlog']:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c1487f-26aa-4fb4-ab57-af7813122f5c",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92511a5a-773d-47ba-8c13-3c7c1fdf52eb",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2feb65-e634-408e-a3f4-9aacaeedffee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "for i in ['soilgrids2020_cec', 'soilgrids2020_phh2o', 'soilgrids2020_sand',\n",
    "          'soilgrids2020_soc', 'soilgrids2020_clay', 'soilgrids2020_ocs_0-30cm',\n",
    "          'soilgrids2020_nitrogen', 'soilgrids2020_cfvo', 'soilgrids2020_ocd',\n",
    "          'soilgrids2020_bdod', 'soilgrids2020_silt', \n",
    "          'soilgrids2020_ocsunc_0-30cm']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax, robust=True)\n",
    "    ax.set_title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918c58fe-4811-46a0-ad95-c5bbb7fb83e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "for i in ['soilgrids2017_ocs_0-30cm', 'soilgrids2017_ocs_30-100cm',\n",
    "          'soilgrids2017_ocs_100-200cm', 'soilgrids2017_bdticm',\n",
    "          'soilgrids2017_bdricm', 'soilgrids2017_bdrlog']:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax, robust=True)\n",
    "    ax.set_title(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
