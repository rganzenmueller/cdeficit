{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fceacb52-5123-4671-840e-76583b20d6ef",
   "metadata": {},
   "source": [
    "# Prepare Copernicus LUC data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfdfa04-9454-41de-a041-8a20ed4d0dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os, time, shutil, rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "from dask.distributed import Lock\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3001680-7643-4daa-bae3-58feb59f6eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data =  '../data/'\n",
    "dir01 = '../paper_deficit/output/01_prep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48bb889f-2934-4552-b2b1-1fa582a5a3c1",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24fae4dc-77b6-4561-8712-f5d35e1ae355",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e29bec-672e-4776-888d-a55a4bdb8e41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=24,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='02:00:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=19)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6c2ac2-be9a-4648-9188-4a18a99f7eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to trim memory of workers\n",
    "def trim_memory() -> int:\n",
    "    import ctypes\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64f03ab4-a2d2-4091-b2d3-6333541ffb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions to prepare copernicus luc data\n",
    "\n",
    "def _open_da_cop_luc(year, ltype):\n",
    "    \"\"\" Open Copernicus LUC TIF file and change NaN-default value to NaN \"\"\"\n",
    "\n",
    "    # dictionary with luc types and orig names\n",
    "    dict_cop_fract = {\n",
    "        'cop_bare': 'Bare-CoverFraction',\n",
    "        'cop_builtup': 'BuiltUp-CoverFraction', \n",
    "        'cop_crops': 'Crops-CoverFraction',\n",
    "        'cop_grass': 'Grass-CoverFraction',\n",
    "        'cop_moss_lichen': 'MossLichen-CoverFraction',\n",
    "        'cop_permanent_water': 'PermanentWater-CoverFraction',\n",
    "        'cop_seasonal_water': 'SeasonalWater-CoverFraction',\n",
    "        'cop_shrub': 'Shrub-CoverFraction',\n",
    "        'cop_snow': 'Snow-CoverFraction',\n",
    "        'cop_tree': 'Tree-CoverFraction'\n",
    "    }\n",
    "    \n",
    "    #read data\n",
    "    if year == 2015:\n",
    "        str_add = '-base_'\n",
    "    if year in [2016, 2017, 2018]:\n",
    "        str_add = '-conso_'\n",
    "    if year == 2019:\n",
    "        str_add = '-nrt_'\n",
    "    \n",
    "    if ltype != 'forest_type':\n",
    "        file_path = (f\"{dir_data}/copernicus_luc/{year}\"\n",
    "                     f\"/PROBAV_LC100_global_v3.0.1_{year}{str_add}\"\n",
    "                     f\"{dict_cop_fract[ltype]}-layer_EPSG-4326.tif\")\n",
    "    if ltype == 'forest_type':\n",
    "        file_path = (f\"{dir_data}/copernicus_luc/{year}\"\n",
    "                     f\"/PROBAV_LC100_global_v3.0.1_{year}{str_add}\"\n",
    "                     f\"Forest-Type-layer_EPSG-4326.tif\")\n",
    "        \n",
    "    da = rioxarray.open_rasterio(file_path,\n",
    "                                 chunks=dict(y=5000, x=5000), lock=False)\n",
    "\n",
    "    # set nan-default value to nan\n",
    "    da = da.where(da!=255).squeeze('band', drop=True)\n",
    "\n",
    "    return da\n",
    "\n",
    "\n",
    "def _prep_da_cop_luc(ltype):\n",
    "    \"\"\" Prepare Copernicus fractional type LUC TIFs for one LUC type across \n",
    "    multiple years \"\"\"\n",
    "\n",
    "    # List of years to process\n",
    "    years = range(2015, 2020)\n",
    "\n",
    "    # Open data for all years and concatenate into an xarray dataset\n",
    "    ds_sub = xr.concat(\n",
    "        [_open_da_cop_luc(year, ltype) \\\n",
    "             .expand_dims(year=[year]) for year in years],\n",
    "        dim='year'\n",
    "    )\n",
    "\n",
    "    # Calculate the mean over the years, round, and set NaN-default values to 255\n",
    "    da_mean = ds_sub.mean('year').round(0).fillna(255).astype(np.uint8)\n",
    "\n",
    "    # Copy attributes from the 2015 dataset\n",
    "    da_mean.attrs = ds_sub.sel(year=2015).attrs\n",
    "\n",
    "    return da_mean\n",
    "\n",
    "\n",
    "def _prep_ds_forest_types():\n",
    "    \"\"\" Prepare Copernicus forest type LUC TIFs \"\"\"\n",
    "\n",
    "    def prep_da_cop_forest(year):\n",
    "        # read data\n",
    "        da = _open_da_cop_luc(year, 'forest_type')\n",
    "        # create dataset with arrays of forest types for one year\n",
    "        ds = xr.Dataset()\n",
    "        ds['cop_forest_unknown'] = xr.where(da == 0, 1, 0).astype('uint8')\n",
    "        ds['cop_forest_enf'] = xr.where(da == 1, 1, 0).astype('uint8')\n",
    "        ds['cop_forest_ebf'] = xr.where(da == 2, 1, 0).astype('uint8')\n",
    "        ds['cop_forest_dnf'] = xr.where(da == 3, 1, 0).astype('uint8')\n",
    "        ds['cop_forest_dbf'] = xr.where(da == 4, 1, 0).astype('uint8')\n",
    "        ds['cop_forest_mixed'] = xr.where(da == 5, 1, 0).astype('uint8')\n",
    "        \n",
    "        return ds\n",
    "\n",
    "    # Prepare arrays for each year using a loop and list comprehension\n",
    "    ds_years = xr.concat(\n",
    "        [prep_da_cop_forest(year).expand_dims(year=[year]) \n",
    "         for year in range(2015, 2020)],\n",
    "        dim='year'\n",
    "    )\n",
    "\n",
    "    # Average over the five years, round, and convert to uint8\n",
    "    ds = ds_years.mean('year').round(0).astype(np.uint8)\n",
    "\n",
    "    # Add attributes to each forest type variable\n",
    "    for var in ds.data_vars:\n",
    "        ds[var].attrs = dict(\n",
    "            band_crs='WGS84 (EPSG:4326)',\n",
    "            missing_value=255,\n",
    "            _FillValue=255.0,\n",
    "            scale_factor=1.0,\n",
    "            add_offset=0.0,\n",
    "            unit='None',\n",
    "            note='Forest Type for all pixels with tree PVC bigger than 1%'\n",
    "        )\n",
    "\n",
    "    # Assign short names using the forest type map\n",
    "    ds['cop_forest_unknown'].attrs['short_name'] = 'Unknown forest type'\n",
    "    ds['cop_forest_enf'].attrs['short_name'] = 'Evergreen needle-leaved'\n",
    "    ds['cop_forest_ebf'].attrs['short_name'] = 'Evergreen broadleaved'\n",
    "    ds['cop_forest_dnf'].attrs['short_name'] = 'Deciduous needle-leaved'\n",
    "    ds['cop_forest_dbf'].attrs['short_name'] = 'Deciduous broadleaved'\n",
    "    ds['cop_forest_mixed'].attrs['short_name'] = 'Mixed'\n",
    "\n",
    "    return ds\n",
    "\n",
    "\n",
    "def prep_copernicus():\n",
    "\n",
    "    \"\"\" Prepare copernicus luc tifs \"\"\"\n",
    "    \n",
    "    # list with copernicus luc types except forest types\n",
    "    list_cop_fract = ['cop_bare', 'cop_builtup', 'cop_crops', 'cop_grass',\n",
    "                      'cop_moss_lichen', 'cop_permanent_water',\n",
    "                      'cop_seasonal_water', 'cop_shrub', 'cop_snow', 'cop_tree']\n",
    "\n",
    "    # list with copernicus forest types\n",
    "    list_cop_ftype = ['cop_forest_unknown', 'cop_forest_enf', 'cop_forest_ebf', \n",
    "                      'cop_forest_dnf', 'cop_forest_dbf', 'cop_forest_mixed']\n",
    "    \n",
    "    # prepare and export luc types except forest types as tif\n",
    "    for i in list_cop_fract:\n",
    "        # Prepare data\n",
    "        da = _prep_da_cop_luc(i)\n",
    "        # Export as tif\n",
    "        da.rio.to_raster(dir01 + i + '.tif', tiled=True)\n",
    "         # Trim memory\n",
    "        client.run(trim_memory)\n",
    "\n",
    "        \n",
    "    # prepare and export luc forest types as tif\n",
    "    for i in list_cop_ftype:\n",
    "        # Prepare data\n",
    "        da = _prep_ds_forest_types()[i]\n",
    "        # Export as tif\n",
    "        da.rio.to_raster(dir01 + i + '.tif', tiled=True)\n",
    "        # Trim memory\n",
    "        client.run(trim_memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d37f4c-c879-42c8-b18b-7cd83aaf374b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare copernicus luc data\n",
    "%time prep_copernicus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "655c685d-f7e1-4a06-9ca6-dca8587bbfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dask cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f43e5d-684d-4717-8ab0-539b9e8c8b3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for 60s for dask client to completely disconnect\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e9a635-8a42-4f49-81a4-eeb3fc235505",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8725bb6-5ff1-4a06-9d5a-9eb1f201d9a1",
   "metadata": {},
   "source": [
    "### Regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedc1e5c-6d1c-481d-b9a3-f18afac045a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regridding function\n",
    "from regrid_high_res_v1_01 import regrid_high_res, prep_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33ce4c7-a7e2-497d-a603-f7adcd670923",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_da(f_source, dir_target, dir_source, dir_out, \n",
    "              size_tiles, fill_value=None, olap=1):  \n",
    "    \"\"\"Regrid large xarray dataarrays.\n",
    "\n",
    "    Args:\n",
    "        f_source (str): The filename (without extension) of the source .tif file to be regridded.\n",
    "        dir_target (str): Directory containing target grid .tif file.\n",
    "        dir_source (str): Directory containing the the source  .tif file.\n",
    "        dir_out (str): Directory to store the output and intermediate files.\n",
    "        size_tiles (int): Size of the regridding tiles in degrees.\n",
    "        fill_value (float, optional): Fill value to use in the regridding process. Defaults to None.\n",
    "        olap (int, optional): Overlap size in degrees for regridding tiles. Defaults to 1.\n",
    "        \n",
    "    Returns:\n",
    "        xarray.Dataset: The combined dataset after regridding.\n",
    "    \"\"\"\n",
    "    # Prepare the target and source data arrays from TIFF files\n",
    "    da_target = prep_tif(dir_target + 'target_grid.tif', 'target_grid')\n",
    "    da_source = prep_tif(dir_source + f_source + '.tif', f_source)\n",
    "    # Regridd source array to target grid\n",
    "    regrid_high_res(da_target, da_source, dir_out,\n",
    "                    account='bm0891', partition='compute',\n",
    "                    size_tiles=size_tiles, olap=olap, fill_value = fill_value,\n",
    "                    type_export='zarr', del_interm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5c74673-39a7-4774-9edb-9e1c4d0fdfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with copernicus luc types except forest types\n",
    "list_cop_fract = ['cop_bare', 'cop_builtup', 'cop_crops', 'cop_grass',\n",
    "                  'cop_moss_lichen', 'cop_permanent_water',\n",
    "                  'cop_seasonal_water', 'cop_shrub', 'cop_snow', 'cop_tree']\n",
    "\n",
    "\n",
    "for i in list_cop_fract:\n",
    "    print(i)\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 15, 255, 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbe069b-487f-417e-99fb-5c02c15e75be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with copernicus forest types\n",
    "list_cop_ftype = ['cop_forest_unknown', 'cop_forest_enf', 'cop_forest_ebf', \n",
    "                  'cop_forest_dnf', 'cop_forest_dbf', 'cop_forest_mixed']\n",
    "\n",
    "for i in list_cop_ftype:\n",
    "    print(i)\n",
    "    %time regrid_da(i, dir01, dir01, dir01, 15, 255, 0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee882b12-dcbe-49d3-bd60-032c85be5d7a",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9583f-b30f-4ae6-a971-0a4412c28922",
   "metadata": {},
   "source": [
    "### Fill nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc7b167-aa44-486e-9b87-87fe18e28ec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(var, dir_out):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the specified variable's dataset using the nearest valid \n",
    "    data, applies a land mask, and exports the result to a new Zarr dataset.\n",
    "\n",
    "    Args:\n",
    "        var (str): Name of the variable to process (e.g., 'temperature', 'precipitation').\n",
    "        dir_out (str): Directory where prepared data is stored and the filled dataset will be exported.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def fill_nans_array(data, invalid):\n",
    "        \"\"\"\n",
    "        Replace invalid (NaN) data cells by the value of the nearest valid data \n",
    "        cell.\n",
    "        \"\"\"\n",
    "        ind = ndimage.distance_transform_edt(invalid,\n",
    "                                             return_distances=False,\n",
    "                                             return_indices=True)\n",
    "        return data[tuple(ind)]\n",
    "\n",
    "    # Paths for input and output\n",
    "    land_mask_path = os.path.join(dir_out, 'ds_prep_copernicus_land_mask.zarr')\n",
    "    var_data_path = os.path.join(dir_out, f'ds_regridded_{var}.zarr')\n",
    "    output_path = os.path.join(dir_out, f'ds_prep_{var}.zarr')\n",
    "\n",
    "    # Read land mask data\n",
    "    da_land = xr.open_zarr(land_mask_path) \\\n",
    "                .chunk(dict(lat=5000, lon=5000)) \\\n",
    "                .copernicus_land_mask \\\n",
    "                .compute()\n",
    "\n",
    "    # Read variable data\n",
    "    da_var = xr.open_zarr(var_data_path)['regridded_' + var]\n",
    "\n",
    "    # Fill nan using function fill_nans_array\n",
    "    # If there are no NaNs, skip filling process\n",
    "    if not da_var.isnull().any():\n",
    "        da_fill = da_var.values  # No filling required\n",
    "    else:\n",
    "        da_fill = fill_nans_array(da_var.values, da_var.isnull().values)\n",
    "\n",
    "    # Create a new Dataset with filled data\n",
    "    ds_filled = xr.Dataset(dict(lat = da_var.lat, lon=da_var.lon))\n",
    "    ds_filled[var] = (('lat', 'lon'), da_fill)\n",
    "\n",
    "    # Apply land mask to the filled data\n",
    "    ds_filled = ds_filled.where(da_land)\n",
    "\n",
    "    # Export the filled dataset to Zarr format\n",
    "    ds_filled.chunk(dict(lat=5000, lon=5000)) \\\n",
    "             .to_zarr(output_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40fecb2-ec51-4027-bd56-5fa0d6576f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# List of luc variables\n",
    "list_cop_fract = ['cop_bare', 'cop_builtup', 'cop_crops', 'cop_grass',\n",
    "                  'cop_moss_lichen', 'cop_permanent_water',\n",
    "                  'cop_seasonal_water', 'cop_shrub', 'cop_snow', 'cop_tree']\n",
    "\n",
    "# List of forest variables\n",
    "list_cop_ftype = ['cop_forest_unknown', 'cop_forest_enf', 'cop_forest_ebf', \n",
    "                  'cop_forest_dnf', 'cop_forest_dbf', 'cop_forest_mixed']\n",
    "\n",
    "# Fill nans\n",
    "for i in [*list_cop_fract, *list_cop_ftype]:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38c1c430-c22d-4ac3-a263-c80f417a2cdd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a7992a2-9272-479c-92e3-4f9f4be15c40",
   "metadata": {},
   "source": [
    "### Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b482ad45-901d-4ec0-a1c0-31622bb71c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "# List of luc variables\n",
    "list_cop_fract = ['cop_bare', 'cop_builtup', 'cop_crops', 'cop_grass',\n",
    "                  'cop_moss_lichen', 'cop_permanent_water',\n",
    "                  'cop_seasonal_water', 'cop_shrub', 'cop_snow', 'cop_tree']\n",
    "\n",
    "for i in list_cop_fract:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "178f421f-ceaa-4f68-bd85-7a4f628851e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "# List of forest variables\n",
    "list_cop_ftype = ['cop_forest_unknown', 'cop_forest_enf', 'cop_forest_ebf', \n",
    "                  'cop_forest_dnf', 'cop_forest_dbf', 'cop_forest_mixed']\n",
    "\n",
    "for i in list_cop_ftype:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
