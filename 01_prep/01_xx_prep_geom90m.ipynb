{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14e37957-000d-4dd5-994f-5997e842b23d",
   "metadata": {},
   "source": [
    "# Prepare geom90m data (Amatulli)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7402d6ce-3730-40e2-b7ee-477dbf80ef61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# libraries\n",
    "import os, time, shutil, rioxarray\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from scipy import ndimage\n",
    "from dask.distributed import Lock\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edfed097-d45f-4dce-b38b-a3b4b09902e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir_data =  '../data/'\n",
    "dir01 = '../paper_deficit/output/01_prep/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce5afb1-9ed4-44b7-8a4e-395d7d41b279",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e1676f3-2f6f-487e-8d18-079074a74b52",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ebef89-d715-4aea-82e5-e2e71998c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "from dask_jobqueue import SLURMCluster\n",
    "from dask.distributed import Client\n",
    "import dask\n",
    "\n",
    "# Initialize dask\n",
    "cluster = SLURMCluster(\n",
    "    queue='compute',                      # SLURM queue to use\n",
    "    cores=24,                             # Number of CPU cores per job\n",
    "    memory='256 GB',                      # Memory per job\n",
    "    account='bm0891',                     # Account allocation\n",
    "    interface=\"ib0\",                      # Network interface for communication\n",
    "    walltime='00:30:00',                  # Maximum runtime per job\n",
    "    local_directory='../dask/',           # Directory for local storage\n",
    "    job_extra_directives=[                # Additional SLURM directives for logging\n",
    "        '-o ../dask/LOG_worker_%j.o',     # Output log\n",
    "        '-e ../dask/LOG_worker_%j.e'      # Error log\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Scale dask cluster\n",
    "cluster.scale(jobs=10)\n",
    "\n",
    "# Configurate dashboard url\n",
    "dask.config.config.get('distributed').get('dashboard').update(\n",
    "    {'link': '{JUPYTERHUB_SERVICE_PREFIX}/proxy/{port}/status'}\n",
    ")\n",
    "\n",
    "# Create client\n",
    "client = Client(cluster)\n",
    "\n",
    "client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652cb095-9198-445f-9f67-e4006dcf678a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to trim memory of workers\n",
    "def trim_memory() -> int:\n",
    "    import ctypes\n",
    "    libc = ctypes.CDLL(\"libc.so.6\")\n",
    "    return libc.malloc_trim(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "780272ae-5b8d-49b7-9fa6-ed98acb7c9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_geom90m():\n",
    "    \n",
    "    \"\"\"Prepare geom90m files for regridding\"\"\"\n",
    "\n",
    "    # list of files\n",
    "    list_files = [i for i in os.listdir(dir_data + 'geomorpho90m/') \n",
    "                  if 'tif' in i]\n",
    "    \n",
    "    for i in list_files:\n",
    "        # file\n",
    "        f_str = (dir_data + 'geomorpho90m/' + i)\n",
    "        # file name\n",
    "        f_name = i.split('_')[1]\n",
    "        \n",
    "        # read file, rename, export as tif\n",
    "        da = rioxarray.open_rasterio(f_str, chunks = dict(y=10000, x=10000)) \\\n",
    "            .rename('geom90m_' + f_name) \\\n",
    "            .drop_vars('spatial_ref') \\\n",
    "            .rio.to_raster(dir01 + 'geom90m_' + f_name + '.tif')\n",
    "        \n",
    "        # release memory\n",
    "        client.run(trim_memory);\n",
    "\n",
    "%time prep_geom90m()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e00a1e-7c4d-4701-82e5-ec88fdde4ea4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close dask cluster\n",
    "cluster.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c933bd50-90af-4bc2-9bf2-12166094c1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wait for 60s for dask client to completely disconnect\n",
    "time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f3c4ca-6cd8-4162-b90f-1ebad20ffee0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01100b48-88ac-49c8-8c02-c64e172b003b",
   "metadata": {},
   "source": [
    "### Regridding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9c0dfe-efe9-42fc-b82a-1b231d3638a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import regridding function\n",
    "from regrid_high_res_v1_01 import regrid_high_res, prep_tif"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ddb47d6-4b62-469a-81c8-8e4afde1fc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regrid_da(f_source, dir_target, dir_source, dir_out, \n",
    "              size_tiles, fill_value=None, olap=1):  \n",
    "    \"\"\"Regrid large xarray dataarrays.\n",
    "\n",
    "    Args:\n",
    "        f_source (str): The filename (without extension) of the source .tif file to be regridded.\n",
    "        dir_target (str): Directory containing target grid .tif file.\n",
    "        dir_source (str): Directory containing the the source  .tif file.\n",
    "        dir_out (str): Directory to store the output and intermediate files.\n",
    "        size_tiles (int): Size of the regridding tiles in degrees.\n",
    "        fill_value (float, optional): Fill value to use in the regridding process. Defaults to None.\n",
    "        olap (int, optional): Overlap size in degrees for regridding tiles. Defaults to 1.\n",
    "        \n",
    "    Returns:\n",
    "        xarray.Dataset: The combined dataset after regridding.\n",
    "    \"\"\"\n",
    "    # Prepare the target and source data arrays from TIFF files\n",
    "    da_target = prep_tif(dir_target + 'target_grid.tif', 'target_grid')\n",
    "    da_source = prep_tif(dir_source + f_source + '.tif', f_source)\n",
    "    # Regridd source array to target grid\n",
    "    regrid_high_res(da_target, da_source, dir_out,\n",
    "                    account='bm0891', partition='compute',\n",
    "                    size_tiles=size_tiles, olap=olap, fill_value = fill_value,\n",
    "                    type_export='zarr', del_interm=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eefbdde-070a-4a5d-a202-ef95124001d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# list with prepared geom90m variable names\n",
    "list_geom90m = ['geom90m_northness', 'geom90m_slope',\n",
    "                  'geom90m_cti', 'geom90m_convergence',\n",
    "                  'geom90m_eastness', 'geom90m_spi']\n",
    "list_geom90m = ['geom90m_eastness', 'geom90m_spi']\n",
    "for i in list_geom90m:\n",
    "    print(i)\n",
    "    if i == 'geom90m_spi':\n",
    "        %time regrid_da(i, dir01, dir01, dir01, 20, 65535)\n",
    "    else:\n",
    "        %time regrid_da(i, dir01, dir01, dir01, 20, -32768)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "177b7fb5-2f19-48a5-a915-e902d90f3007",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715cbcf9-dfc4-4fc0-a175-194aa290e082",
   "metadata": {},
   "source": [
    "### Fill nans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d35192de-5e4b-448b-bb11-3b91ae411960",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nans(var, dir_out):\n",
    "    \"\"\"\n",
    "    Fills NaN values in the specified variable's dataset using the nearest valid \n",
    "    data, applies a land mask, and exports the result to a new Zarr dataset.\n",
    "\n",
    "    Args:\n",
    "        var (str): Name of the variable to process (e.g., 'temperature', 'precipitation').\n",
    "        dir_out (str): Directory where prepared data is stored and the filled dataset will be exported.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "\n",
    "    def fill_nans_array(data, invalid):\n",
    "        \"\"\"\n",
    "        Replace invalid (NaN) data cells by the value of the nearest valid data \n",
    "        cell.\n",
    "        \"\"\"\n",
    "        ind = ndimage.distance_transform_edt(invalid,\n",
    "                                             return_distances=False,\n",
    "                                             return_indices=True)\n",
    "        return data[tuple(ind)]\n",
    "\n",
    "    # Paths for input and output\n",
    "    land_mask_path = os.path.join(dir_out, 'ds_prep_copernicus_land_mask.zarr')\n",
    "    var_data_path = os.path.join(dir_out, f'ds_regridded_{var}.zarr')\n",
    "    output_path = os.path.join(dir_out, f'ds_prep_{var}.zarr')\n",
    "\n",
    "    # Read land mask data\n",
    "    da_land = xr.open_zarr(land_mask_path) \\\n",
    "                .chunk(dict(lat=5000, lon=5000)) \\\n",
    "                .copernicus_land_mask \\\n",
    "                .compute()\n",
    "\n",
    "    # Read variable data\n",
    "    da_var = xr.open_zarr(var_data_path)['regridded_' + var]\n",
    "\n",
    "    # Fill nan using function fill_nans_array\n",
    "    # If there are no NaNs, skip filling process\n",
    "    if not da_var.isnull().any():\n",
    "        da_fill = da_var.values  # No filling required\n",
    "    else:\n",
    "        da_fill = fill_nans_array(da_var.values, da_var.isnull().values)\n",
    "\n",
    "    # Create a new Dataset with filled data\n",
    "    ds_filled = xr.Dataset(dict(lat = da_var.lat, lon=da_var.lon))\n",
    "    ds_filled[var] = (('lat', 'lon'), da_fill)\n",
    "\n",
    "    # Apply land mask to the filled data\n",
    "    ds_filled = ds_filled.where(da_land)\n",
    "\n",
    "    # Export the filled dataset to Zarr format\n",
    "    ds_filled.chunk(dict(lat=5000, lon=5000)) \\\n",
    "             .to_zarr(output_path, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "898471af-87ea-45b8-910b-00d4a6bf02e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# list with prepared geom90m variable names\n",
    "list_geom90m = ['geom90m_northness', 'geom90m_slope',\n",
    "                  'geom90m_cti', 'geom90m_convergence',\n",
    "                  'geom90m_eastness', 'geom90m_spi']\n",
    "\n",
    "for i in list_geom90m:\n",
    "    %time fill_nans(i, dir01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8363825b-8c0e-42de-9e4f-36194296c6dc",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "038dc0bd-f9c0-42d3-b6da-548bcd022459",
   "metadata": {},
   "source": [
    "### Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c59fb85-e70d-4742-a308-48df8ce97364",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot to check\n",
    "# List with prepared geom90m variable names\n",
    "list_geom90m = ['geom90m_northness', 'geom90m_slope',\n",
    "                  'geom90m_cti', 'geom90m_convergence',\n",
    "                  'geom90m_eastness', 'geom90m_spi']\n",
    "\n",
    "# Plot\n",
    "for i in list_geom90m:\n",
    "    fig, ax = plt.subplots(figsize=(10, 5), ncols=1, nrows=1)\n",
    "    xr.open_zarr(dir01 + 'ds_prep_' + i + '.zarr')[i] \\\n",
    "        .plot.imshow(ax=ax)\n",
    "    ax.set_title(i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
