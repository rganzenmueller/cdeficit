{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53edc76c-307e-4105-9fdc-c228144c1f8c",
   "metadata": {},
   "source": [
    "# Get feature importance of random forest models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff777755-8073-4008-9a9d-561ef9ed9f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import dask.dataframe as dd\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2d722a-fb98-411b-b381-2c330226e14e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Directories\n",
    "dir02 = '../paper_deficit/output/02_dbase/'\n",
    "dir03 = '../paper_deficit/output/03_rf/'\n",
    "dir03p = os.path.join(dir03 + 'files_params/')\n",
    "dir03i = os.path.join(dir03 + 'files_importance/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f3ffc6-1cbd-4b2b-b62f-8df15ef90181",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51851b5d-dc5f-433f-8ba4-c4ad19a6d1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get database\n",
    "dbase = dd.read_parquet(dir02 + 'df_dbase.parquet')\n",
    "\n",
    "# Explanatory variables\n",
    "vars_exp = ['geom90m_convergence', 'geom90m_cti', 'geom90m_eastness',\n",
    "            'geom90m_northness', 'geom90m_slope', 'geom90m_spi',\n",
    "            'soilgrids2017_bdricm', 'soilgrids2017_bdrlog',\n",
    "            'soilgrids2017_bdticm', \n",
    "            'soilgrids2020_cec', 'soilgrids2020_cfvo', 'soilgrids2020_clay', \n",
    "            'soilgrids2020_phh2o', 'soilgrids2020_sand', 'soilgrids2020_silt',\n",
    "            'worldclim_bio1', 'worldclim_bio3', 'worldclim_bio4',\n",
    "            'worldclim_bio5', 'worldclim_bio6', 'worldclim_bio12', \n",
    "            'worldclim_bio13', 'worldclim_bio14', 'worldclim_bio15', \n",
    "            'worldclim_elev']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fca6d32a-bb42-47cc-8fe7-f8f89b5ee772",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_forest_feature_imp(var_tar, scen):\n",
    "\n",
    "    \"\"\"\n",
    "    Calculate Feature importances for 10 best performing models and export\n",
    "    as csv file\n",
    "    \"\"\"\n",
    "\n",
    "    def get_feature_importance(rank):\n",
    "        \"\"\"\n",
    "        Calculate feature importance for one model\n",
    "        \"\"\"\n",
    "        # Filter parameters for the current rank\n",
    "        df_params_rank = df_params[df_params.rank_test_score == rank]\n",
    "        \n",
    "        rfr = RandomForestRegressor(\n",
    "            min_samples_leaf=df_params_rank.min_samples_leaf.item(),\n",
    "            max_features=df_params_rank.max_features.item(),\n",
    "            n_estimators=df_params_rank.n_estimators.item(),\n",
    "            random_state=df_params_rank.random_state.item(),\n",
    "            n_jobs=-1)\n",
    "            \n",
    "        rfr.fit(X_train, y_train)\n",
    "        \n",
    "        return rfr.feature_importances_\n",
    "\n",
    "    \n",
    "    # Get training data\n",
    "    df_train = dbase[dbase['train_' + scen] == True][[var_tar, *vars_exp]] \\\n",
    "        .repartition(partition_size='200 MiB')\n",
    "        \n",
    "    # Split training data in features and target/label\n",
    "    X_train = df_train[vars_exp].persist()\n",
    "    y_train = df_train[var_tar].persist()\n",
    "    \n",
    "    # Get dataframe with parameters and ranks\n",
    "    params_file = os.path.join(dir03p, f'df_params_rank_{var_tar}_{scen}.csv')\n",
    "    df_params = pd.read_csv(params_file)\n",
    "\n",
    "    # Dataframe to store feature importances\n",
    "    df_imp = pd.DataFrame(dict(var_exp = df_train[vars_exp].columns))\n",
    "    # Calculate feature importances for each of the 10 best performing models\n",
    "    for rank in range(1, 11):\n",
    "        df_imp[f\"rank_{rank}\"] = get_feature_importance(rank)\n",
    "    # Calculate mean, min, and max importance value for each feature\n",
    "    df_imp_sel = df_imp[[f\"rank_{i}\" for i in range(1, 11)]]\n",
    "    df_imp = df_imp.assign(imp_mean = df_imp_sel.mean(axis=1),\n",
    "                           imp_min = df_imp_sel.min(axis=1),\n",
    "                           imp_max = df_imp_sel.max(axis=1)\n",
    "                          )\n",
    "    \n",
    "    # Construct output file name\n",
    "    output_file = os.path.join(dir03i, f'df_feature_imp_{var_tar}_{scen}.csv')\n",
    "                      \n",
    "    # Export dataframe as csv file\n",
    "    df_imp.to_csv(output_file, index=False, mode='w')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604aa492-7261-466d-be2b-c7d236c209e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agbc\n",
    "# Calculate feature importance of 10 best performing models\n",
    "for var_tar in ['agbc_min', 'agbc_mean', 'agbc_max']:\n",
    "    for scen in ['prim', 'secd']:\n",
    "        %time random_forest_feature_imp(var_tar, scen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecdfa9eb-51eb-4790-aa7d-73180c72333d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bgbc\n",
    "# Calculate feature importance of 10 best performing models\n",
    "for var_tar in ['bgbc_min', 'bgbc_mean', 'bgbc_max']:\n",
    "    for scen in ['prim', 'secd']:\n",
    "        %time random_forest_feature_imp(var_tar, scen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc638c4-5bab-42a6-87e1-e17728b503e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Soc\n",
    "# Calculate feature importance of 10 best performing models\n",
    "for var_tar in ['soc_min', 'soc_mean', 'soc_max']:\n",
    "    for scen in ['prim', 'secd']:\n",
    "        %time random_forest_feature_imp(var_tar, scen)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 (deficit)",
   "language": "python",
   "name": "deficit_python312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
